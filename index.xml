<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ZecSec: Zcash Ecosystem Security</title><description>Zcash Ecosystem Security Support</description><link>https://zecsec.com/</link><language>en</language><copyright>Copyright 2022, Calvin Tran</copyright><lastBuildDate>Fri, 11 Aug 2023 01:00:00 -0700</lastBuildDate><generator>Hugo - gohugo.io</generator><docs>http://cyber.harvard.edu/rss/rss.html</docs><atom:link href="https://zecsec.com//atom.xml" rel="self" type="application/atom+xml"/><item><title>If you used libbitcoin-explorer (bx) to generate your seed phrase, rotate it ASAP!</title><link>https://zecsec.com/posts/milk-sad/</link><description>&lt;p>A critical vulnerability has been discovered in &lt;code>libbitcoin-explorer&lt;/code>
(command-line tool &lt;code>bx&lt;/code>), known as &lt;a href="https://milksad.info/">&amp;ldquo;milk sad&amp;rdquo;&lt;/a>.&lt;/p>
&lt;p>&lt;strong>If at any point in the past, you may have used the &lt;code>bx seed&lt;/code> tool to generate
your crypto wallet&amp;rsquo;s seed phrase, you must IMMEDIATELY generate a new seed
phrase using an up-to-date secure wallet and move your funds to the new
wallet.&lt;/strong>&lt;/p>
&lt;p>The bug in &lt;code>bx seed&lt;/code> is simple: it used only the system&amp;rsquo;s time as a source of
randomness when generating seed phrases. As a result, &lt;code>bx seed&lt;/code> could only ever
produce one of around 4 billion seed phrases. This set of 4 billion seed phrases
can easily be re-generated by attackers, and funds are currently being stolen
from wallets using one of these seed phrases.&lt;/p>
&lt;p>Similar bugs have existed in Cake Wallet and Trust Wallet, see the &lt;a href="https://milksad.info/disclosure.html">details in
the milk sad discoverers&amp;rsquo; technical
writeup&lt;/a>. If you used those wallets, I
recommend re-generating a new seed phrase as well.&lt;/p>
&lt;p>As far as I know, other wallets are not affected by this bug. To protect
yourself against these kinds of bugs, be sure to only use a wallet which has
undergone an independent security review.&lt;/p></description><author>trandcanh@gmail.com (Calvin Tran)</author><guid>https://zecsec.com/posts/milk-sad/</guid><pubDate>Fri, 11 Aug 2023 01:00:00 -0700</pubDate></item><item><title>Security Engineering: Learning from Safety-Critical Disciplines</title><link>https://zecsec.com/posts/security-engineering/</link><description>&lt;p>At Zcon4, I gave a talk that summarizes the results of my Zcash ecosystem
security grant and provides an overview of security engineering, drawing on
knowledge from safety-critical industries such as aviation.&lt;/p>
&lt;p>This talk should be useful to anyone working to set up a security program in
their organization or looking to improve their team&amp;rsquo;s security practices.
Experienced security engineers may be interested in the safety engineering
concepts that also apply to security engineering.&lt;/p>
&lt;h2 id="the-talk">The Talk&lt;/h2>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/fgkFrxiB14g" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>You can also &lt;a href="https://docs.google.com/presentation/d/1gq-JOhLkmvlebkh5RBCTZBZwNBoxZ_ioVmgAsMKkC1Q/edit?usp=sharing">view the slides here&lt;/a>.&lt;/p></description><author>trandcanh@gmail.com (Calvin Tran)</author><guid>https://zecsec.com/posts/security-engineering/</guid><pubDate>Sun, 30 Jul 2023 01:00:00 -0700</pubDate></item><item><title>ZecSec's Q1 2023 Transparency Report</title><link>https://zecsec.com/posts/2023-q1-transparency-report/</link><description>&lt;p>The ZecSec project publishes quarterly transparency reports in order to ensure
accountability and to help the Zcash community understand how its funds are
being spent. This is the report for Q1 of 2023.&lt;/p>
&lt;p>Note that some of these reports may be delayed, and some information may be
redacted or slightly modified, in order to prevent the disclosure of unresolved
security bugs.&lt;/p>
&lt;p>The current
&lt;a href="https://forum.zcashcommunity.com/t/zcash-ecosystem-security-lead/42090">grant&lt;/a>
allows me to bill $1000 USD per day, up to a maximum of $17,000 per month, up to
12 total months. The sections below break down and explain my invoices for Q1
2023. The previous transparency report, for Q4 2022, can be found
&lt;a href="https://zecsec.com/posts/2022-q4-transparency-report/">here&lt;/a>.&lt;/p>
&lt;h2 id="january">January&lt;/h2>
&lt;p>In January, the bulk of my time went into a security audit of
&lt;a href="https://github.com/zcash/lightwalletd">lightwalletd&lt;/a>. I also did a quick review
of &lt;a href="https://zgo.cash/">ZGo&lt;/a> and did some research on secure messaging
cryptography, thinking about how Zcash&amp;rsquo;s memo field could be extended to better
support messaging use cases.&lt;/p>
&lt;table class="table table-striped table-bordered">
&lt;thead>
&lt;tr>
&lt;th>Days&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>12&lt;/td>
&lt;td>Security audit of lightwalletd&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>Secure messaging cryptography research&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2&lt;/td>
&lt;td>Quick security review of ZGo&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2&lt;/td>
&lt;td>Miscellaneous time including office hours, PR review, and preparing the last transparency report&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Total days: 17, Total paid: $17,000.&lt;/p>
&lt;h2 id="february">February&lt;/h2>
&lt;p>In February, the main item I spent time on was thinking about how we could
&lt;a href="https://zecsec.com/posts/making-zcash-light-wallets-faster-and-more-private/">change the Zcash protocol to make transaction syncing more performant and
scalable&lt;/a>.
I was also put in touch with some SGX/ORAM researchers interested in using the
technology to help solve Zcash&amp;rsquo;s performance issues, which led me to writing a
&lt;a href="https://zecsec.com/posts/risk-analysis-of-intel-sgx-and-other-tees/">risk analysis of SGX and other Trusted Execution
Environments&lt;/a>.&lt;/p>
&lt;table class="table table-striped table-bordered">
&lt;thead>
&lt;tr>
&lt;th>Days&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>2&lt;/td>
&lt;td>lightwalletd audit remediation coordination/assistance&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>3&lt;/td>
&lt;td>SGX / TEE / ORAM research leading to the &lt;a href="https://zecsec.com/posts/risk-analysis-of-intel-sgx-and-other-tees/">risk analysis blog post&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>6&lt;/td>
&lt;td>&lt;a href="https://zecsec.com/posts/making-zcash-light-wallets-faster-and-more-private/">Scalable transaction detection protocol design&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>3&lt;/td>
&lt;td>Quick security audit of free2z&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>3&lt;/td>
&lt;td>Helping investigate disclosed &lt;a href="https://electriccoin.co/blog/new-releases-remediate-memory-exhaustion-vulnerability-in-zcash/">memory exhaustion bugs&lt;/a> in zcashd&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Total days: 17, Total paid: $17,000.&lt;/p>
&lt;h2 id="march">March&lt;/h2>
&lt;p>In March, I audited &lt;a href="https://github.com/Zondax/ledger-zcash">Zondax&amp;rsquo;s shielded hardware wallet
code&lt;/a>. I also reviewed the ZIPs for
&lt;a href="https://github.com/zcash/zips/pull/680">Zcash Shielded Assets&lt;/a> (note that I
missed &lt;a href="https://forum.zcashcommunity.com/t/grant-update-zcash-shielded-assets-monthly-updates/41153/42?u=earthrise">a
bug&lt;/a>!).&lt;/p>
&lt;table class="table table-striped table-bordered">
&lt;thead>
&lt;tr>
&lt;th>Days&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>12&lt;/td>
&lt;td>Security audit of Zondax&amp;rsquo;s shielded Zcash Ledger app code&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>Researching Identity-Based Encryption for scalable protocol designs&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>3&lt;/td>
&lt;td>ZSA ZIPs review&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>Office hours and other miscellaneous items&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Total days: 17, Total paid: $17,000.&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>In Q1 of 2023, I completed two major audits (of lightwalletd and Zondax&amp;rsquo;s
shielded hardware wallet), several quick audits (of ZGo, free2z, and the ZSA
ZIPs), and published research on a scalable protocol design and an analysis of
the risks of using SGX/ORAM to fix Zcash&amp;rsquo;s performance issues.&lt;/p>
&lt;p>In total, I invoiced 51 days and received $51,000 paid in ZEC.&lt;/p>
&lt;p>If you have questions about the work that was done or have suggestions for
future priorities, you can either email me at &lt;a href="mailto:zecsec@defuse.ca">zecsec@defuse.ca&lt;/a> or reply on &lt;a href="https://forum.zcashcommunity.com/t/zcash-ecosystem-security-lead/42090">the
grant&amp;rsquo;s forum
thread&lt;/a>.&lt;/p></description><author>trandcanh@gmail.com (Calvin Tran)</author><guid>https://zecsec.com/posts/2023-q1-transparency-report/</guid><pubDate>Tue, 18 Apr 2023 01:00:00 -0700</pubDate></item><item><title>A Simple Threat Model for Zcash Shielded Hardware Wallets</title><link>https://zecsec.com/posts/threat-model-for-zcash-hardware-wallets/</link><description>&lt;p>In this post, we&amp;rsquo;ll share a simple threat model for Zcash shielded hardware
wallets. This is useful for informing users about which security and privacy
properties they can expect to rely on when using a shielded hardware wallet and
to help security auditors understand what counts as a &amp;ldquo;security bug.&amp;rdquo;&lt;/p>
&lt;p>To define a threat model for Zcash shielded hardware wallets, we consider the
following scenario:&lt;/p>
&lt;ol>
&lt;li>The user initially sets up their hardware wallet using a PC or smartphone
which is fully compromised by the attacker. The user is careful to back up their
seed phrase and never enter it into the compromised PC/phone.&lt;/li>
&lt;li>The user sends funds to their hardware wallet, using the addresses displayed
on its dedicated screen.&lt;/li>
&lt;li>The user spends funds, carefully checking the transaction details displayed
on the dedicated screen are correct, and only approving the transaction on the
device when all details are as expected.&lt;/li>
&lt;/ol>
&lt;p>Within this scenario, we define the threat model in terms of what expectations
the user has regarding the attacker who has compromised their PC/phone,
following the process of &lt;a href="https://github.com/defuse/ictm">Invariant-Centric Threat
Modelling&lt;/a>.&lt;/p>
&lt;p>We expect that the attacker &lt;em>CAN&lt;/em>:&lt;/p>
&lt;ol>
&lt;li>Prevent the user from using their wallet on that compromised PC/phone (but not
others).&lt;/li>
&lt;li>Steal viewing keys which let the attacker permanently compromise the privacy
of the wallet&amp;rsquo;s addresses.&lt;/li>
&lt;li>Cause funds being spent by the user to be stolen, if the user did not
carefully verify the transaction details on the device&amp;rsquo;s screen.&lt;/li>
&lt;li>Cause funds that the user is receiving to be stolen, if they did not verify
their address on the device&amp;rsquo;s screen or if they used the compromised PC/phone to
transmit their address (e.g. the attacker could replace the user&amp;rsquo;s address with
their own after the user pastes it into an exchange&amp;rsquo;s website).&lt;/li>
&lt;li>Cause transactions to be generated in a way that weakens privacy (e.g. by
causing randomized signatures to not be randomized, or by tagging transactions
such that the sender&amp;rsquo;s identity is revealed on the public blockchain).&lt;/li>
&lt;/ol>
&lt;p>The user expects that the attacker &lt;em>CANNOT&lt;/em>:&lt;/p>
&lt;ol>
&lt;li>Obtain the spend authority keys for any of the user&amp;rsquo;s addresses.&lt;/li>
&lt;li>Cause the user&amp;rsquo;s funds to become unspendable.&lt;/li>
&lt;li>Spend the user&amp;rsquo;s funds without physical approval on the hardware device.&lt;/li>
&lt;li>Produce a transaction whose semantics are different in any way from what was approved through the device&amp;rsquo;s display, including changing the destination of funds being spent, the amount of funds being spent, or the fee amount.&lt;/li>
&lt;li>Cause the hardware wallet to display, as its own address, any other address, such as one an attacker controls.&lt;/li>
&lt;li>Cause an official-looking message to be displayed on the hardware wallet&amp;rsquo;s display (which could be used for phishing).&lt;/li>
&lt;li>Permanently prevent the hardware wallet from functioning with another uncompromised PC/phone.&lt;/li>
&lt;/ol>
&lt;p>In addition to these specialized considerations for shielded hardware wallets, a
PC or smartphone wallet app that interfaces with a shielded hardware wallet is
expected to fall under the scope of the &lt;a href="https://zcash.readthedocs.io/en/latest/rtd_pages/wallet_threat_model.html">Zcash Wallet App Threat
Model&lt;/a>.&lt;/p></description><author>trandcanh@gmail.com (Calvin Tran)</author><guid>https://zecsec.com/posts/threat-model-for-zcash-hardware-wallets/</guid><pubDate>Sat, 15 Apr 2023 00:00:00 -0700</pubDate></item><item><title>Risk Analysis of Intel's SGX and Other TEEs</title><link>https://zecsec.com/posts/risk-analysis-of-intel-sgx-and-other-tees/</link><description>&lt;p>Intel&amp;rsquo;s &lt;a href="https://www.intel.com/content/www/us/en/developer/tools/software-guard-extensions/overview.html">Software Guard eXtensions (SGX)&lt;/a> is a Trusted Execution Environment (TEE) technology built into some Intel CPUs. It is a special mode of operation that the processor can be put into that intends to allow for integrity-protected and confidentiality-protected processing, even under the assumption that the machine is fully compromised (i.e. the attacker has root access).&lt;/p>
&lt;p>Using cryptographic keys baked into the sillicon, SGX intends to allow the processor to remotely &amp;ldquo;attest&amp;rdquo; to its secure execution state, so that clients can be assured that they are interacting with safe code (the &amp;ldquo;enclave&amp;rdquo;) and can provide secrets to that code without them being vulnerable to theft even by root users of the system.&lt;/p>
&lt;p>In recent years, researchers have produced attacks that result in a complete breakage of SGX&amp;rsquo;s security guarantees. The variety of methods used in the attacks and the frequency with which new bugs are being discovered in Intel processors calls into question SGX&amp;rsquo;s ability to provide a secure Trusted Execution Environment.&lt;/p>
&lt;p>&lt;em>What are these attacks, and are there any alternative TEE designs that fare better?&lt;/em>&lt;/p>
&lt;h2 id="recent-history-of-attacks-on-sgx">Recent History of Attacks on SGX&lt;/h2>
&lt;p>Prior to 2018, attacks on SGX enclaves had all relied on vulnerabilities in specific software written for SGX and did not break SGX itself. Attackers either found remote-code-execution type bugs in specific enclaves or exploited side-channel leakage in enclave code that was not carefully written to not leak data through timing and memory access patterns.&lt;/p>
&lt;p>In 2018, this changed when the &lt;a href="https://foreshadowattack.eu/">Foreshadow attack&lt;/a> broke SGX to the point where attackers could forge remote attestations, violating both the integrity and confidentiality of any computations running inside SGX.&lt;/p>
&lt;p>Foreshadow is aptly-named; it preceeded a series of attacks which all broke SGX in similarly-bad ways. All of the following bugs have been mitigated with hardware patches and/or microcode updates; the goal of the survey below is to give a feel for the state-of-the-art in SGX attack research to inform your risk assessment when considering using SGX in your application.&lt;/p>
&lt;h3 id="foreshadow-----2018">Foreshadow &amp;mdash; 2018&lt;/h3>
&lt;p>The &lt;a href="https://foreshadowattack.eu/">Foreshadow&lt;/a> attack exploits a transient execution bug in Intel processors to read an SGX enclave&amp;rsquo;s protected memory.&lt;/p>
&lt;p>The way this is done is that the attacker runs a piece of code that attempts to read memory within the region allocated to the enclave. Normally, these reads should return -1 values so that the attacker cannot access the enclave&amp;rsquo;s secrets. However, if (a) the attacker sets up memory access permissions such that the access produces an exception rather than a -1 value and (b) the value at the memory location is in the processor&amp;rsquo;s L1 cache, a race condition causes the processor to &lt;em>transiently&lt;/em> execute the attacker&amp;rsquo;s code on the actual value residing in the enclave&amp;rsquo;s memory.&lt;/p>
&lt;p>&lt;em>Transient execution&lt;/em> is a performance optimization feature whereby the processor optimistically continues running code, even if that code would generate an exception (e.g. it gets run in parallel with a memory access-control check that fails) and even if the code would ordinarly not be executed at all (e.g. the processor mis-predicts which branch will be taken).&lt;/p>
&lt;p>Most of the effects of the transiently-executed instructions are rolled back. However, the attacker, who controls the transiently-executed code, has enough time to encode a value they want to leak into the state of the processor&amp;rsquo;s cache by reading a memory location that depends on the value. Their transiently-executed read puts the secret-value-dependent location into the cache. After the roll-back, another attacking process reads the memory locations that might have been transiently accessed. The location that was put into the cache will be read quickly, whereas the locations corresponding to the other possible values will be slow. As a result, the attacker learns the value that the transiently-executed code briefly had access to.&lt;/p>
&lt;p>By combining a transient execution attack with some other tricks, Foreshadow&amp;rsquo;s authors were able to leak the secrets from Intel&amp;rsquo;s quoting enclave, an enclave that is instrumental in the remote attestation process. The leaked secrets allowed for forgery of remote attestations, meaning they could obtain any of the secrets clients would send into any enclave and arbitrarily corrupt the integrity of any enclave&amp;rsquo;s execution.&lt;/p>
&lt;h3 id="plundervolt-----2019">Plundervolt &amp;mdash; 2019&lt;/h3>
&lt;p>In &lt;a href="https://plundervolt.com/">Plundervolt&lt;/a>, researchers exploited a software interface for controlling the processor&amp;rsquo;s voltage and frequency to inject faults into SGX computations. By lowering the voltage, they found that they could cause long-lived instructions like multiplications and AES round computations to be computed incorrectly.&lt;/p>
&lt;p>They demonstrated how to use these faults to (a) recover an RSA secret key for a certain implementation of RSA, (b) recover an AES key when the encryption is performed using Intel&amp;rsquo;s hardware-accelerated AES-NI instruction set, and (c) create memory-corruption type bugs in otherwise bug-free enclaves by glitching the multiply instructions in size calculations so that wrong amounts of memory were allocated. They did not break the remote attestation process, but since remote attestation relies on similar cryptography, it&amp;rsquo;s plausible that a well-engineered Plundervolt attack could have done so.&lt;/p>
&lt;h3 id="sgaxe-----2020">SGAxe &amp;mdash; 2020&lt;/h3>
&lt;p>&lt;a href="https://sgaxe.com/files/SGAxe.pdf">SGAxe&lt;/a> uses &lt;a href="https://cacheoutattack.com/">CacheOut&lt;/a>, yet another transient execution attack, to leak the keys needed to forge SGX attestations.&lt;/p>
&lt;p>The CacheOut bug in particular highlights the nacency of our collective understanding of, and ability to fix, processor bugs. Prior to CacheOut&amp;rsquo;s discovery, the previously-discovered transient execution bugs &lt;a href="https://meltdownattack.com/">Spectre and Meltdown&lt;/a> had already been patched by Intel. Despite the class of transient execution bugs being known for some time prior, the researchers behind CacheOut found that the patching was incomplete and that transient execution bugs still existed.&lt;/p>
&lt;p>Interestingly, CacheOut leaks data from an undocumented data path in the processor. The researchers were able to leak the data&amp;mdash;experimentally&amp;mdash;without being aware of the true reason for the leakage. This is an example of how Intel&amp;rsquo;s secrecy regarding its processor designs can be a hinderance to security research yet does not prevent the discovery of new attacks.&lt;/p>
&lt;h3 id="æpic-leak-----2022">ÆPIC Leak &amp;mdash; 2022&lt;/h3>
&lt;p>&lt;a href="https://aepicleak.com/">ÆPIC Leak&lt;/a> exploits a bug in the memory-mapping of &lt;a href="https://en.wikipedia.org/wiki/Advanced_Programmable_Interrupt_Controller">APIC&lt;/a> registers.&lt;/p>
&lt;p>The APIC&amp;rsquo;s registers are mapped into normal memory space so that the operating system&amp;rsquo;s kernel can read and modify them. However, the registers are split into 4-byte values and those values are aligned along 64-byte boundaries. In-between the values are regions that software is never meant to read or write to. Technically, it&amp;rsquo;s &amp;ldquo;undefined behaviour&amp;rdquo; if software ever does read or write there.&lt;/p>
&lt;p>What the researchers found was that actually, reading from those regions would sometimes return whatever data happened to be in the processor&amp;rsquo;s L1 cache. They combined this bug with some other tricks to get regions of SGX enclaves&amp;rsquo; memory into the L1 cache, allowing them to dump any enclave&amp;rsquo;s memory and registers. By attacking Intel&amp;rsquo;s quoting enclave, they were able to get the keys needed to forge remote attestations, breaking the confidentiality and integrity of all enclaves.&lt;/p>
&lt;h2 id="other-tees-alternatives-to-sgx">Other TEEs, Alternatives to SGX&lt;/h2>
&lt;h3 id="amds-sev">AMD&amp;rsquo;s SEV&lt;/h3>
&lt;p>AMD&amp;rsquo;s alternative to Intel&amp;rsquo;s SGX is its Secure Encrypted Virtualization (SEV), which aims to encrypt virtual machines&amp;rsquo; memory so that their memory contents are not accessible to the hypervisor they are running on.&lt;/p>
&lt;p>AMD&amp;rsquo;s processors were vulnerable to many of the same kinds of transient execution attacks as Intel&amp;rsquo;s processors were (e.g. Spectre), so SEV is likely vulnerable to similar kinds of attacks. Not as much security research exists on AMD&amp;rsquo;s SEV as does for Intel&amp;rsquo;s SGX, nevertheless attack research has shown that its remote &lt;a href="https://dl.acm.org/doi/10.1145/3319535.3354216">attestation can be foiled&lt;/a> and &lt;a href="https://dl.acm.org/doi/10.1145/3460120.3485253">virtual machines can be impersonated&lt;/a>, eroding the trust that remote clients might place in SEV-encrypted virtual machines.&lt;/p>
&lt;h3 id="arms-trustzone">ARM&amp;rsquo;s TrustZone&lt;/h3>
&lt;p>ARM CPUs include a similar technolgy called TrustZone which &lt;a href="https://ieeexplore.ieee.org/document/9152801">has similarly been catastrophically broken by bugs in the past&lt;/a>. In contrast to SGX, the known attacks against TrustZone have mainly been remote-code-execution style attacks against the large corupus of software that runs inside and maintains TrustZone&amp;rsquo;s TEE, as well as &lt;a href="https://duo.com/decipher/new-side-channel-attack-extracts-private-keys-from-some-qualcomm-chips">side-channel attacks targeting cryptography&lt;/a> running within TrustZone. That&amp;rsquo;s not a guarantee that CPU bugs don&amp;rsquo;t exist. In fact, voltage glitching can be used to break TrustZone&amp;rsquo;s security, but these kinds of attacks have been &lt;a href="https://developer.arm.com/documentation/ka005159/1-0">deemed to be out of scope&lt;/a> as TrustZone only aims to defend against software-based attacks, not physical access attacks.&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>Considering all of these attacks together, it is clear that TEE designs have not yet matured enough to be relied on for security-critical applications. Based on the rate at which bugs are being found, we can conclude that our scientific understanding of processor bugs is still in its infancy, as is our understanding of how to build bug-free TEEs. We should expect more bugs to be found in the coming years.&lt;/p>
&lt;p>In the case of SGX, recent bugs have not only broken specific enclaves with poor side-channel defenses, they have catastrophically broken all of SGX&amp;rsquo;s security guarantees, with demonstrations of forged remote attestations. Developers wishing to rely on SGX should design their applications under the assumption that SGX will become vulnerable to a publicized bug in the near future, potentially for as long as 6-12 months as microcode/hardware fixes are developed. It might also be wise to assume that nation-state actors are aware of undisclosed processor bugs in order to retain the capability of breaking SGX and other TEEs.&lt;/p>
&lt;p>&lt;em>Will it ever be safe to rely on TEEs?&lt;/em>&lt;/p>
&lt;p>If highly-resourced attackers with physical access are in your threat model, I would say &lt;em>no&lt;/em>. Since the processor must &lt;em>somewhere&lt;/em> operate on the enclave&amp;rsquo;s data, that data must physically reside within the processor, so it is vulnerable to theft by a sophisticated-enough attack; TEEs secure against highly-resourced attackers with physical access are fundamentally impossible&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>For less-critical applications, I would wait for the bug discovery rate to fall
much lower, say to one attestation-breaking bug discovered every three-or-so
years, before placing a significant amount of trust in any TEE. A low bug
discovery rate doesn&amp;rsquo;t guarantee security, but you still can benefit from a TEE
when the cost of finding and exploiting a bug becomes greater than the value an
attacker would gain by breaking the TEE in your security model.&lt;/p>
&lt;p>If you&amp;rsquo;re only using a TEE as a defense-in-depth measure, there is no harm in doing so, just be sure to weigh the additional development costs against other ways you might invest in security.&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>The exception to this is fully-homomorphic encryption (FHE), which uses cryptographic techniques, rather than trusted hardware, to ensure private execution. FHE is still impractical for most use cases.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description><author>trandcanh@gmail.com (Calvin Tran)</author><guid>https://zecsec.com/posts/risk-analysis-of-intel-sgx-and-other-tees/</guid><pubDate>Fri, 10 Mar 2023 01:00:00 -0700</pubDate></item><item><title>Making Zcash Light Wallets Faster and More Private</title><link>https://zecsec.com/posts/making-zcash-light-wallets-faster-and-more-private/</link><description>&lt;p>In this post, I&amp;rsquo;m going to sketch changes to the Zcash protocol that would allow
light wallets to be both &lt;em>much faster&lt;/em> and &lt;em>more private&lt;/em> than they currently
are. By writing this post, I hope to start a discussion about how we can
pragmatically fix the privacy leaks in the current light wallet protocol and at
the same time vastly improve light wallet performance.&lt;/p>
&lt;p>&lt;em>&lt;strong>Warning:&lt;/strong> There are almost certainly security bugs in the protocol described below that I haven&amp;rsquo;t caught,
so please don&amp;rsquo;t implement this without careful thought!&lt;/em>&lt;/p>
&lt;h2 id="two-kinds-of-wallet">Two Kinds of Wallet&lt;/h2>
&lt;p>The proposed design would allow users to make a choice between two kinds of
wallet depending on their preferences for privacy versus performance.&lt;/p>
&lt;h3 id="option-1-privacy-optimized-wallet">Option 1: Privacy-Optimized Wallet&lt;/h3>
&lt;p>A &lt;em>privacy-optimized wallet&lt;/em> uses trial decryption to find its notes, just like a
full node does. The wallet is careful to always download every transaction,
including all of the data it might ever need such as memo fields. As a result,
the externally-visible behavior of the wallet reveals no information about how
many transactions it is receiving. The cost, of course, is that trial-decrypting
every transaction in the blockchain is bandwidth- and compute-intensive, so
this option is best suited to wallets running on PCs and servers.&lt;/p>
&lt;p>This option is for users who need extra-strong privacy guarantees, including
&lt;em>address unlinkability privacy&lt;/em>, where even an adversary who knows a wallet&amp;rsquo;s
address and has compromised the light wallet server cannot find out which wallet
the address belongs to. In the performance-optimized option, we will give up
this privacy property; this is likely necessary, as we will discuss later.&lt;/p>
&lt;h3 id="option-2-performance-optimized-wallet">Option 2: Performance-Optimized Wallet&lt;/h3>
&lt;p>In the proposed design, a &lt;em>performance-optimized wallet&lt;/em> relies on a set of
partially-trusted &lt;em>Mix Authority&lt;/em> servers as well as a partially-trusted
&lt;em>Detection Server&lt;/em> to quickly detect their transactions. What these servers do
is explained later on.&lt;/p>
&lt;p>A performance-optimized wallet has the following performance and privacy
properties:&lt;/p>
&lt;h4 id="performance-properties">Performance Properties&lt;/h4>
&lt;ul>
&lt;li>The wallet must authenticate and sync the note commitment and nullifier sets.&lt;/li>
&lt;li>When the wallet is launched, it has to download and trial-decrypt &lt;em>at most
the current day&amp;rsquo;s worth of transactions&lt;/em>.&lt;/li>
&lt;li>For all days previous to the current one, the wallet can fetch its
transactions quickly from its Detection Server in a way that &lt;em>does not require
the Detection Server to scan over all transactions for each user&lt;/em>, i.e. a single
Detection Server could reliably serve thousands or more users.&lt;/li>
&lt;li>If the wallet&amp;rsquo;s chosen Detection Server goes down, or the user switches
Detection Servers, the new Detection Server will have to perform trial-detection
(a linear scan over all new transactions) on the user&amp;rsquo;s behalf until the user
updates their addresses.&lt;/li>
&lt;li>At least one of the Mix Authorities must be operational, otherwise wallets
must find their transactions by downloading everything and using
trial-decryption.&lt;/li>
&lt;li>The wallet must still update the witnesses for their unspent notes as usual.&lt;/li>
&lt;li>The sizes of addresses and transactions are moderately increased.&lt;/li>
&lt;/ul>
&lt;h4 id="privacy-properties">Privacy Properties&lt;/h4>
&lt;ul>
&lt;li>When implemented carefully, even global passive adversaries observing
encrypted network traffic learn nothing about when or how many transactions the
wallet receives, i.e. the traffic-analysis side-channels on the receiving side
are eliminated.&lt;/li>
&lt;li>When a malicious or compromised Detection Server knows one of its users'
wallet&amp;rsquo;s addresses, it can find out which user it is (i.e. identified by their IP address).&lt;/li>
&lt;li>If the Detection Server is compromised but the Mix Authority servers are
honest and uncompromised, the attacker can learn &lt;em>how many&lt;/em> transactions the
wallet receives each day, but not &lt;em>which ones&lt;/em>.&lt;/li>
&lt;li>If a Mix Authority is compromised but the wallet&amp;rsquo;s Detection Server remains
honest and secure, the attacker learns nothing about which transactions belong
to which wallets.&lt;/li>
&lt;li>Only if &lt;em>both&lt;/em> a Mix Authority &lt;em>and&lt;/em> the wallet&amp;rsquo;s Detection Server are
compromised, the attacker learns exactly which transactions belong to the
wallet.&lt;/li>
&lt;/ul>
&lt;p>When addresses are kept secret, the design also lets wallets granularly delegate
detection authority, i.e. only grant detection authority for certain days, which
further limits the effects of any server compromise that is detected and
corrected. Notably, when addresses are kept secret, even if the private state of
all Mix Authorities and Detection Servers leaks, the attacker can group
transactions within a day by wallet, but they still cannot tie those groups to
wallets&amp;rsquo; identities&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> or connect the groups from different days.&lt;/p>
&lt;p>Although the performance-optimized protocol intentionally trades-off privacy and
adds a dependency on &amp;ldquo;1-of-2&amp;rdquo; trusted servers for the sake of performance, its
privacy properties are still much better than the reality today where the light
wallet server can learn precisely which transactions belong to which wallets,
confirm address ownership, and more&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>The partially-trusted Mix Authorities can eventually be replaced by a
multi-party computation protocol or by a proper mixnet, eliminating the need to
use centralized services and increasing security (e.g. by requiring any
attackers to compromise multiple Mix Authorities rather than just one). One
possibility is to get proof-of-stake validators to do the mixing in a future
proof-of-stake protocol.&lt;/p>
&lt;h2 id="protocol">Protocol&lt;/h2>
&lt;p>In the suggested protocol, Zcash blocks are divided into daily &amp;ldquo;epochs.&amp;rdquo;
Performance-optimized wallets retain their privacy for the current epoch by
downloading and trial-decrypting all transactions within the current epoch. To
detect transactions in previous epochs, the protocol is augmented as follows.&lt;/p>
&lt;p>The Zcash consensus rule maintainers (ECC and ZF) take community input to
maintain a permissioned list of Mix Authorities and the Zcash consensus rules
publish a set of Mix Authority public keys \(\{M_{i}\} \) for the Mix
Authorities that are active in the current epoch.&lt;/p>
&lt;h3 id="address-generation">Address Generation&lt;/h3>
&lt;p>To construct an address, the wallet first generates all of the usual components
of an address as normal, then derives secrets \(s, r, dsk\) from their viewing
key.&lt;/p>
&lt;p>Then, the wallet obtains a verifiably-randomized public key from their Detection Server:&lt;/p>
&lt;ol>
&lt;li>The Detection Server publishes their public key \(S = [ssk]G_1 \) for all
users to see. Users check that they all see the same \(S\), e.g. using a
public forum or by having it hard-coded into their wallets.&lt;/li>
&lt;li>The wallet sends \(r\) to the Detection Server.&lt;/li>
&lt;li>The Detection Server computes \(G_r = GroupHash(r)\) and \(S_r =
[ssk]G_r\) and sends these values to the wallet, along with a zero-knowledge
proof that \(S_r\) was computed correctly.&lt;/li>
&lt;li>The wallet verifies the zero-knowledge proof.&lt;/li>
&lt;/ol>
&lt;p>This allows the Detection Server to use its \(ssk\) to efficiently decrypt
messages sent to any \(S_r\) generated through this process without letting
the Detection Server determine &lt;em>which&lt;/em> particular \(S_r\) the message was
encrypted to. (This is similar to how diversified addresses work, except we
don&amp;rsquo;t want the Detection Server to be able to know which &amp;ldquo;diversifier&amp;rdquo; was
used.) This is done to ensure that we never give the Detection Server unlimited
detection capabilities as long as the address is kept secret from them. Checking
the consistency of \(S\) between users ensures that the Detection Server is
not using unique private keys in order to identify users.&lt;/p>
&lt;p>Next, the wallet generates two extra elements for their address:&lt;/p>
&lt;ol>
&lt;li>A transaction tagging key \(K_{TT} = H(s)\), where \(H\) is a
collision-resistant PRF.&lt;/li>
&lt;li>A detection public key \( D = [dsk]G_2 \).&lt;/li>
&lt;/ol>
&lt;p>Given the wallet&amp;rsquo;s normal address \(addr \), the wallet&amp;rsquo;s address is now
\((addr, G_r, S_r, K_{TT}, D)\).&lt;/p>
&lt;p>If the wallet chooses to be privacy-optimized, i.e. to opt-out of efficient
detection, it sets \(G_r, S_r, K_{TT}, D\) all to random (but valid for their type)
values.&lt;/p>
&lt;h3 id="sending-transactions">Sending Transactions&lt;/h3>
&lt;p>Given a wallet&amp;rsquo;s address \((addr, G_r, S_r, K_{TT}, D)\), a sender constructs a
transaction as follows, in addition to all of the normal steps of constructing a
transaction.&lt;/p>
&lt;p>\(e\) is the current epoch number, \(Enc(pk, ptxt, ad, [G = G_3, esk
\leftarrow \$, epk = [esk]G])\) is a DH-based key-private authenticated
public key encryption algorithm with additional data which can be the same as
the one used for Orchard note encryption, and \(PRF^T, PRF^D\) are
collision-resistant PRFs.&lt;/p>
&lt;ol>
&lt;li>Let \(C\) be the usual note ciphertext and construct an additional note
ciphertext \(C^L\) that uses a fresh random ephemeral key&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>.&lt;/li>
&lt;li>Generate an ephemeral keypair \(esk, epk = [esk]G_r\).&lt;/li>
&lt;li>Construct the transaction tag \(T = PRF^{T}(K_{TT}, G_r||e) \).&lt;/li>
&lt;li>Construct a proof \(\pi\) that for public inputs \(T, epk\), the
transaction creator knows witnesses \(G_r, esk\) such that \(T\) was
calculated as above and \(epk = [esk]G_r\), i.e. \(epk\) uses the same base
as was used in the calculation of \(T\).&lt;/li>
&lt;li>Construct the tag ciphertext \(C^T = Enc(S_r, T||\pi, &amp;ldquo;tct&amp;rdquo; || e, G_r, esk, epk)\).&lt;/li>
&lt;li>Construct the epoch detection public key \(D^* = D + [PRF^D(K_{TT}, e)]G_2\).&lt;/li>
&lt;li>Construct the detection ciphertext \(C^D = Enc(D^*, &amp;ldquo;true&amp;rdquo;, &amp;ldquo;dct&amp;rdquo; || e)\)&lt;/li>
&lt;li>Construct the post-mix ciphertext \(C^{PoM} = (C^T, C^D, C^L)\).&lt;/li>
&lt;li>Construct the pre-mix ciphertexts \(C^{PrM}_i = Enc(M_i, C^{PoM}, &amp;ldquo;mix&amp;rdquo; || e)\).&lt;/li>
&lt;/ol>
&lt;p>The new note ciphertext is \( (C, \{C_i^{PrM}\}) \). All of the other
transaction components are constructed as usual.&lt;/p>
&lt;h3 id="mixing-and-detection">Mixing and Detection&lt;/h3>
&lt;p>At the end of each epoch, each Mix Authority \(i \) collects the list of
pre-mix ciphertexts \( \{ C_{i,j}^{PrM} \} \) for that epoch, decrypts them,
and publishes and signs the &lt;em>sorted and deduplicated&lt;/em> list of post-mix ciphertexts. By
sorting and deduplicating the list, the Mix Authority makes it impossible for
others to tell which pre-mix ciphertexts (outputs on the blockchain)
correspond with which post-mix ciphertexts. In other words, without additional
information, each post-mix ciphertext is hiding in an epoch-sized anonymity set
of shielded outputs.&lt;/p>
&lt;p>The deduplication is necessary to prevent attackers from &amp;ldquo;tagging&amp;rdquo; ciphertexts
through the mixing process by repeating them a unique number of times. The
\(&amp;ldquo;mix&amp;rdquo;||e\) additional data is necessary to prevent attackers from
replaying honestly-created pre-mix ciphertexts across epochs to circumvent the
mixing. The sorting needs to happen in constant time, otherwise the running time
of the sorting algorithm could leak information about connections between
pre-mix and post-mix ciphertexts.&lt;/p>
&lt;p>As long as &lt;em>at least one&lt;/em> Mix Authority is online, the post-mix ciphertexts will
become available. As long as &lt;em>all&lt;/em> Mix Authorities are honest and uncompromised,
the mapping between transactions and post-mix ciphertexts will remain secret.
(These properties can be strengthened by onion-encrypting the pre-mix
ciphertexts to follow different paths through multiple levels of Mix
Authorities, as is done in a mixnet.)&lt;/p>
&lt;p>Once at least one of the Mix Authorities have published the list of post-mix
ciphertexts, all of the Detection Servers obtain and authenticate the list.
Then, for each \(C^{PoM}_i = (C^T_i, C^D_i, C^L_i)\), they use their secret
key \(ssk\) to try to decrypt \(C^T_i\). If this works, they obtain \(T\)
and \(\pi\), and after checking \(\pi\), they enter \(C^{L}_i\) into their
database indexed on \(T\).&lt;/p>
&lt;h3 id="receiving-transactions">Receiving Transactions&lt;/h3>
&lt;p>All wallets must always download and authenticate the entire note commitment and
nullifier sets. The protocol then allows wallets to detect their incoming
transactions in three different ways.&lt;/p>
&lt;h4 id="1-trial-decryption">1. Trial Decryption&lt;/h4>
&lt;p>First, the wallet can use its viewing key to trial-decrypt the regular note
ciphertext \(C \) as is done currently. This remains possible even if all of
the Mix Authorities and Detection Servers go offline.&lt;/p>
&lt;h4 id="2-indexed-detection">2. Indexed Detection&lt;/h4>
&lt;p>Second, the fastest way for a wallet to obtain its transactions for an epoch
\(e\) is to ask its Detection Server for a random nonce \(n\) and then
prove in zero-knowledge, for public parameters \(e, n, T\), that it knows the
secrets \(s, r\) such that \(T = PRF^T(H(s), GroupHash(r)||e)\).&lt;/p>
&lt;p>The Detection Server authenticates the user by checking the zero-knowledge proof
and the freshness of the nonce and then provides the wallet with all of the
\(C^L\) ciphertexts it has indexed on \(T\) using a constant-bandwidth protocol.&lt;/p>
&lt;h4 id="3-non-indexed-detection">3. Non-Indexed Detection&lt;/h4>
&lt;p>If the wallet&amp;rsquo;s Detection Server has gone offline, the wallet has a third option
for efficiently retrieving its transactions from a different Detection Server.
To do this, it constructs its epoch detection secret key \(dsk + PRF^D(K_{TT},
e)\) and provides it and the epoch number \(e\) to the new Detection Server.
The Detection Server uses this key to trial-decrypt each \(C^D\) in the epoch, and
when decryption succeeds, it provides the wallet with the corresponding \(C^L\) over
a constant-bandwidth protocol.&lt;/p>
&lt;p>When using indexed or non-indexed detection, the wallet obtains and decrypts the
\(C^L\) ciphertexts then authenticates their contents by re-computing the note
commitment and checking that the same commitment appears in the authenticated
note commitment set at a position within the expected epoch.&lt;/p>
&lt;h3 id="security-analysis">Security Analysis&lt;/h3>
&lt;h4 id="address-unlinkability">Address Unlinkability&lt;/h4>
&lt;p>When a wallet&amp;rsquo;s Detection Server knows the wallet&amp;rsquo;s address, the detection
server can identify which of its users owns the wallet (e.g. by IP address).&lt;/p>
&lt;p>This seems unavoidable when the wallet doesn&amp;rsquo;t download everything, because with
the address known, the Detection Server can always send thousands of
transactions to the address. Assuming this doesn&amp;rsquo;t cause &lt;em>all&lt;/em> wallets to
download thousands of transactions worth of data, the victim wallet then either has
to make itself distinguishable from other wallets by downloading thousands of
transactions worth of data or fail to receive many of its transactions,
suggesting a DoS attack on addresses is possible. Either &lt;em>all&lt;/em> wallets download
lots of data when
&lt;em>any&lt;/em> wallet needs to, DoS attacks on addresses are possible, or wallets with
addresses that receive lots of transactions are identifiable by the amount of
data the Detection Server sends to them.&lt;/p>
&lt;p>Only the Detection Server observes this leakage, not a global passive adversary,
because the Detection Server always sends detected transactions over a
constant-bandwidth protocol (e.g. in fixed-sized packets sent at regular
intervals).&lt;/p>
&lt;p>&lt;em>Open Question:&lt;/em> Can we prove that this limitation applies to all possible
protocols?&lt;/p>
&lt;h4 id="granular-delegation-of-detection-authority">Granular Delegation of Detection Authority&lt;/h4>
&lt;p>When the user&amp;rsquo;s chosen Detection Server knows their wallet&amp;rsquo;s address, it can
perpetually find out which \(C^L\) belong to the wallet. This is because,
knowing \(G_r, K_{TT}\), it can re-compute the address&amp;rsquo;s tags for each epoch.
This is always possible for any design that allows the Detection Server to
&amp;ldquo;bucket&amp;rdquo; transactions for future retrieval by wallets: the Detection Server can
send many transactions to the known address and watch which &amp;ldquo;bucket&amp;rdquo; grows. As
long as the Mix Authorities are secure, even a Detection Server that knows a
wallet&amp;rsquo;s address will only learn &lt;em>how many&lt;/em> transactions the wallet receives
each day.&lt;/p>
&lt;p>When the wallet&amp;rsquo;s address is kept secret from the Detection Server, the
Detection Server is unable to reliably detect transactions for the wallet in
epochs other than the ones explicitly requested by the wallet.&lt;/p>
&lt;p>In the indexed detection case, this is because given the epoch-specific tag \(T
= PRF^T(K_{TT}, G_r||e)\), the Detection Server cannot compute the tag for
any other epoch without knowing \(K_{TT}\). For other epochs, the
Detection Server only learns, &amp;ldquo;one of my users&amp;rsquo; wallets received \(n\)
transactions&amp;rdquo; but it does not know which wallet until the wallet reveals its tag
for that epoch. The anonymity set is lower-bounded by wallets using the same
Detection Server whose addresses are also secret and who have not provided their
epoch-specific tags. This is especially useful if a Detection Server is known to
be compromised and all users stop using it. Additionally, any user of the
Detection Server can increase the size of the anonymity set by registering
addresses to which they send random amounts of &amp;ldquo;dummy&amp;rdquo; transactions.&lt;/p>
&lt;p>Since the Detection Server only ever needs ephemeral access to the tags wallets
request, the Detection Server can be careful to delete all trace of the
relationship between wallets&amp;rsquo; identities and their requested tags after the
requests have been served. This ensures that if the Detection Server&amp;rsquo;s state
gets leaked, it will be apparent how &lt;em>mix-anonymized ciphertexts&lt;/em> are grouped
together within epochs, but for addresses that were kept secret, those groupings
(daily transaction counts) will not be tied to wallets&amp;rsquo; identities in any way.
If Mix Authorities&amp;rsquo; keys are leaked too, it will be apparent how &lt;em>transactions&lt;/em>
are grouped daily, but those groups won&amp;rsquo;t be linked to wallets&amp;rsquo; identities when
addresses are kept secret.&lt;/p>
&lt;p>In the non-indexed case, the Detection Server learns \(dsk + PRF^D(K_{TT},
e)\). Without knowing \(K_{TT}\), they cannot recover \(dsk\) or any of the
other per-epoch detection secret keys. This is useful in case the user&amp;rsquo;s main
Detection Server goes down and they are forced to use a less-trustworthy one. As
long as their address is kept secret, the new Detection Server is only granted
detection authority for a limited number of epochs.&lt;/p>
&lt;p>Using Identity-Based Encryption (IBE), the non-indexed case can probably be improved
so that it does not rely on address secrecy. I am currently investigating the
impact IBE would have on address sizes.&lt;/p>
&lt;p>In all cases, it is impossible to link a pre-mix ciphertext to a post-mix
ciphertext unless either you can decrypt a message encrypted to a Mix
Authority&amp;rsquo;s public key key or you created the transaction yourself. This
guarantees that even if the Detection Server learns a user&amp;rsquo;s address, their true
notes are still hiding in an epoch-sized anonymity set. At most, they learn how
many notes the user receives in each epoch, and as explained earlier, can
identify the address owner (by IP address) when they connect and ask for their
transactions.&lt;/p>
&lt;h4 id="obfuscating-the-number-of-transactions-received">Obfuscating the number of transactions received&lt;/h4>
&lt;p>As long as the Mix Authorities are secure, wallets can send random amounts of
transactions to themselves to obscure the total number of transactions that they
receive. The Detection Server is unable to tell which transactions are
self-transactions, so they would see the distribution \(R + F\), where \(R\)
is the distribution of real transactions the wallet receives and \(F\) is the
distribution of fake transactions the wallet generates to itself. This would
require wallets to be online daily to send fake transactions in each epoch, or
they could delegate the task to a third-party service by providing their
address.&lt;/p>
&lt;h4 id="lack-of-post-quantum-privacy">Lack of post-quantum privacy&lt;/h4>
&lt;p>The suggested protocol changes are &lt;em>not&lt;/em> post-quantum private. Large-scale
quantum computers would be able to reveal the connection between pre-mix and
post-mix ciphertexts. Additionally, quantum computers would be able to decrypt
the tags. So, even when addresses are kept secret, quantum computers would be
able to group transactions with identical tags within epochs. In other words, a
quantum attacker has the same capabilities as an attacker who had compromised
all Mix Authorities and Detection Servers. This is a &lt;em>weakening&lt;/em> of Zcash&amp;rsquo;s
post-quantum privacy properties, since currently Zcash is conjectured to be
post-quantum private when addresses are kept secret.&lt;/p>
&lt;h4 id="the-need-for-pi-in-step-4-of-transaction-generation">The need for \(\pi\) in step 4 of transaction generation&lt;/h4>
&lt;p>The Detection Server checks the proof \(\pi\) generated in step 4 and makes
sure that wallets fetching tags know \(r\) in order to prevent senders from
being able to learn which Detection Server an address uses.&lt;/p>
&lt;p>Without these checks, an attacker (a) could use a &lt;em>different&lt;/em> \(G_{r*}\) from
the same server as the encryption base while still computing the tag with
\(G_r\) and the victim would receive the transaction if and only if the
attacker used the same server, or (b) could send a transaction to themselves (a
\(K_{TT}\) for which they know \(s\)) using the victim&amp;rsquo;s \(G_r\) for both
the encryption and \(T\); they would receive the transaction if and only if
they used the same server.&lt;/p>
&lt;p>In case (a), \(\pi\) ensures that the tag \(T\) is always computed using the
same base as was used for the encryption, so if an attacker tried this, the
victim would not receive the transaction because they would never request the
attacker-generated tags that use a different base. In case (b), the attacker is
not able to look up tags constructed using the victim&amp;rsquo;s \(G_r\) because the
Detection Server requires them to prove knowledge of \(r\) when requesting a
tag.&lt;/p>
&lt;p>This kind of attack is possible in general for any protocol by DDoSing a
Detection Server and observing if that prevents the victim from receiving their
transaction. However, using a DDoS attack to carry out the attack would be much
more obvious than exploiting the weaknesses that would exist without these
checks.&lt;/p>
&lt;p>With these checks in place, the protocol has better privacy properties for receivers than the
state-of-the-art mixnet design
&lt;a href="https://github.com/zcash/zcash/issues/288#issuecomment-658348272">Loopix&lt;/a>,
which requires senders to know which Detection Server (&amp;ldquo;providers&amp;rdquo; in their
terminology) the recipient uses.&lt;/p>
&lt;h3 id="optimizations-and-improvements">Optimizations and Improvements&lt;/h3>
&lt;p>\(s\) and \(r\) can be combined by using \(G_s = GroupHash(s)\) instead of
\(G_r = GroupHash(r)\). However, to do this, the address registration process
must be modified so that the wallet only sends \(G_s\) to the server (so that
it doesn&amp;rsquo;t disclose \(s\)), and the wallet must prove in zero knowledge that
\(G_s = GroupHash(s)\) (otherwise the registration API becomes a
decryption oracle!).&lt;/p>
&lt;p>The same protocol can also be used for transaction inputs so that wallets can
detect their spends efficiently.&lt;/p>
&lt;p>Identity-based encryption could also potentially be used for Detection Servers'
public keys so that their private keys can be kept offline and only loaded onto
the live server as needed, and old private keys can be deleted after they are no
longer needed. This would provide stronger forward-security and
backward-security properties in case a well-operated Detection Server is
compromised.&lt;/p>
&lt;p>Since, assuming address secrecy, indexed lookups across days cannot be linked,
wallets can perform each lookup over a fresh Tor circuit to further obfuscate
the number of transactions their wallet receives over time. This would be vulnerable to
global passive adversaries and to timing correlation attacks, however.&lt;/p>
&lt;p>If the additional privacy and compromise-resistance properties for the indexed
detection case that rely on address secrecy are deemed not to be very useful,
the protocol can be greatly simplified using &lt;a href="https://github.com/zcash/zcash/issues/288#issuecomment-658348272">Daira Hopwood&amp;rsquo;s detection key
design&lt;/a>.&lt;/p>
&lt;p>The Zcash consensus rules could require wallets to pay a fee to the mix
authorities, so that they are sustainably funded.&lt;/p>
&lt;p>In the proposed design, wallets only learn about the shielded outputs they
receive, and not other parts of the transaction. In order to learn the other
transaction components, e.g. to be able to compute the txid, the sender would
need to encrypt this additional data to the wallet through the mixing process,
and the wallet would need to authenticate it somehow.&lt;/p>
&lt;p>Full nodes can prune all of the pre-mix ciphertexts to save on storage space.&lt;/p>
&lt;p>The Mix Authority public keys should be rotated regularly to reduce the impact
of a compromise.&lt;/p>
&lt;h2 id="sender-privacy">Sender Privacy&lt;/h2>
&lt;p>While the above design provides pretty good privacy for transaction receivers,
it leaves open a privacy weakness for transaction senders.&lt;/p>
&lt;p>Suppose, for example, that a controversial charity publishes their viewing key
for accounting purposes and that a user wishes to donate to the charity.
Alternatively, suppose that the viewing key was not published but was
compromised by an attacker.&lt;/p>
&lt;p>When the user&amp;rsquo;s wallet broadcasts their donation transaction, the attacker can
use the viewing key to try to decrypt the transaction and learn that the user is
donating to the charity.&lt;/p>
&lt;p>In general, anyone who has compromised the light wallet server can find out who
is sending transactions to them or to any address whose viewing key they know.&lt;/p>
&lt;p>To prevent this, we need to add sender anonymity. This could be done by re-using
the same Mix Authorities to batch and shuffle transactions before they are
broadcast publicly into the blockchain, e.g. using &lt;a href="https://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/piotrowska">Loopix&lt;/a>&amp;rsquo;s Poisson mixing strategy.&lt;/p>
&lt;p>Wallets can also use Loopix&amp;rsquo;s concepts of &amp;ldquo;loop cover&amp;rdquo; and &amp;ldquo;drop cover&amp;rdquo; traffic
to respectively obscure the number of transactions received (as described above)
and eliminate information leakage about how many transactions are sent.&lt;/p>
&lt;p>The &amp;ldquo;drop cover&amp;rdquo; traffic would never need to be added to the blockchain, and if
the same Mix Authorities are used for sending and receiving, the &amp;ldquo;loop cover&amp;rdquo;
traffic for obscuring receive counts need not be entered into the blockchain
either.&lt;/p>
&lt;h2 id="conclusion-whats-next">Conclusion; What&amp;rsquo;s Next?&lt;/h2>
&lt;p>By implementing something like the above protocol, Zcash light wallets could
find their notes much faster while being much more private than they are today.
The drawbacks to this design are that (a) address sizes and transaction sizes
are increased, (b) the protocol relies on a permissioned set of mix authorities,
(c) daily received-transaction-count data resides on Detection Servers and is
vulnerable to being leaked, and (d) the protocol needs three additional
zero-knowledge proofs whose circuits need to be designed and implemented.
Ideally, the permissioned set of mixes would eventually be replaced by a proper
permissionless mixnet, e.g. with the mixing being done by proof-of-stake
validators.&lt;/p>
&lt;p>The next steps for me are to,&lt;/p>
&lt;ol>
&lt;li>learn about identity-based encryption to see if it&amp;rsquo;s reasonable to eliminate
the address secrecy requirement for granular delegation in the non-indexed detection case,&lt;/li>
&lt;li>think more carefully about the protocol design to see if it can be simplified
and optimized and to ensure there aren&amp;rsquo;t any vulnerabilities, and&lt;/li>
&lt;li>collect feedback and write a ZIP.&lt;/li>
&lt;/ol>
&lt;p>If you are a cryptographer, please try to break the protocol!&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>Assuming the Detection Server never logs users&amp;rsquo; IP addresses along with
the tags users look up, and that the Detection Server&amp;rsquo;s database retains no
trace of the order in which tags are looked up.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>See the &lt;a href="https://zcash.readthedocs.io/en/latest/rtd_pages/wallet_threat_model.html">Zcash Wallet App Threat
Model&lt;/a>
for details about the current light wallet privacy weaknesses.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3">
&lt;p>The format of \(C^L\) has to be a bit different than \(C\) because of
&lt;a href="https://zips.z.cash/zip-0212">ZIP 212&lt;/a>; changing rseed would change rcm, which
we don&amp;rsquo;t want, so the defenses in ZIP 212 need to be implemented differently for
\(C^L\).&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description><author>trandcanh@gmail.com (Calvin Tran)</author><guid>https://zecsec.com/posts/making-zcash-light-wallets-faster-and-more-private/</guid><pubDate>Thu, 02 Mar 2023 01:00:00 -0700</pubDate></item><item><title>ZecSec's Q4 2022 Transparency Report</title><link>https://zecsec.com/posts/2022-q4-transparency-report/</link><description>&lt;p>In order to ensure accountability and to help the Zcash community understand how
its funds are being spent, the ZecSec project will be posting quarterly
transparency reports.&lt;/p>
&lt;p>Note that some of these reports may be delayed, and some information may be
redacted, in order to prevent the disclosure of unresolved security bugs.&lt;/p>
&lt;p>The currently-approved
&lt;a href="https://forum.zcashcommunity.com/t/zcash-ecosystem-security-lead/42090">grant&lt;/a>
allows me to bill $1000 USD per day, up to a maximum of $17,000 per month, up to
12 total months. The sections below break down and explain my invoices for Q4
2022.&lt;/p>
&lt;h2 id="september--october">September &amp;amp; October&lt;/h2>
&lt;p>In September and October my focus was on auditing Ywallet. Ywallet was a
priority because it had not yet received any security review and it was one of
the only wallets that functioned in the face of the high transaction load
problem. The report from this audit is available &lt;a href="https://zecsec.com/posts/ywallet-audit-published/">here&lt;/a>.&lt;/p>
&lt;table class="table table-striped table-bordered">
&lt;thead>
&lt;tr>
&lt;th>Days&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>Setting up build environments, skimming over grants/projects, staying up to date on the forums.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>Reviewing various Zcash wallets for a potential DoS bug reported by ZingoLabs.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>8&lt;/td>
&lt;td>Auditing Ywallet&amp;rsquo;s zcash-sync library.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>5&lt;/td>
&lt;td>Auditing Ywallet itself.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>Delivering the Ywallet audit report and answering questions.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>0.5&lt;/td>
&lt;td>Setting up this website.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>0.5&lt;/td>
&lt;td>Reviewing ZIP 317 for security and privacy.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Total days: 17, Total paid: $17,000.&lt;/p>
&lt;h2 id="november">November&lt;/h2>
&lt;p>In November, I audited zecwallet-lite-cli, the transaction processing library
used by ZecWallet-Lite. This paves the way for a future audit of ZecWallet-Lite
itself. I also looked at the customizations that were made to the version of
lightwalletd that ZecWallet-Lite uses.&lt;/p>
&lt;table class="table table-striped table-bordered">
&lt;thead>
&lt;tr>
&lt;th>Days&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>Catching up on forums, planning, setting up Calendly for office hours.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>8&lt;/td>
&lt;td>Auditing zecwallet-lite-cli.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>Reviewing changes to lightwalletd in aditapk00/lightwalletd.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>Helping debug zcashd v5.3.0 build issues and getting the Arch Linux package maintainer to update the package.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>0.5&lt;/td>
&lt;td>Writing &lt;a href="https://zecsec.com/posts/scalable-private-money-needs-scalable-private-messaging/">Scalable Private Money Needs Scalable Anonymous Messaging&lt;/a>.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Total days: 11.5, Total paid: $11,500.&lt;/p>
&lt;h2 id="december">December&lt;/h2>
&lt;p>In December, I focused on planning for the new year. I quickly surveyed every
Zcash-related project that I could find and collected a list of past security
audits, research, and notable bugs. I published the first edition of the &lt;a href="https://zecsec.com/overview/">Zcash Ecosystem Security Overview&lt;/a> and a tentative &lt;a href="https://zecsec.com/posts/zecsec-roadmap-for-2023/">roadmap for 2023&lt;/a>.&lt;/p>
&lt;table class="table table-striped table-bordered">
&lt;thead>
&lt;tr>
&lt;th>Days&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>8&lt;/td>
&lt;td>Surveying all Zcash-related projects, preparing the ecosystem security overview and roadmap.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2&lt;/td>
&lt;td>Checking the Ywallet bug fixes and publishing the Ywallet audit report.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Total days: 10, Total paid: $10,000.&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>In Q4 of 2022, I completed two major audits of Ywallet and zecwallet-lite-cli. I
also contributed to a number of other security efforts such as performing
shorter security reviews of various projects, helping to investigate bugs,
collecting past security research, and writing up my research into options for
privately scaling Zcash.&lt;/p>
&lt;p>In total, I invoiced for 38.5 days and was paid $38,500 in ZEC.&lt;/p>
&lt;p>If you have questions about the work that was done or have suggestions for
future priorities, you can either email me at &lt;a href="mailto:zecsec@defuse.ca">zecsec@defuse.ca&lt;/a> or ask on &lt;a href="https://forum.zcashcommunity.com/t/zcash-ecosystem-security-lead/42090">the
grant&amp;rsquo;s forum
thread&lt;/a>.&lt;/p></description><author>trandcanh@gmail.com (Calvin Tran)</author><guid>https://zecsec.com/posts/2022-q4-transparency-report/</guid><pubDate>Fri, 27 Jan 2023 01:00:00 -0700</pubDate></item><item><title>ZecSec Roadmap for 2023</title><link>https://zecsec.com/posts/zecsec-roadmap-for-2023/</link><description>&lt;p>Happy New Year Zcash!&lt;/p>
&lt;p>For me, the days leading up to the new year are always a time of reflection and
planning. In that spirit, I&amp;rsquo;ve laid out a tentative roadmap for the ZecSec
project in 2023.&lt;/p>
&lt;h2 id="upcoming-audits">Upcoming Audits&lt;/h2>
&lt;h3 id="1-lightwalletd">1. Lightwalletd&lt;/h3>
&lt;p>All Zcash light wallets rely on the
&lt;a href="https://github.com/zcash/lightwalletd">lightwalletd&lt;/a> project to obtain
transaction information and to broadcast transactions to the network. Despite
its central importance to the Zcash ecosystem, it has never been subjected to a
third-party audit. I&amp;rsquo;ll begin the year with a thorough security review of its
entire codebase.&lt;/p>
&lt;h3 id="2-zondax">2. Zondax&lt;/h3>
&lt;p>Shielded hardware wallets have been a long time coming. Now, &lt;a href="https://docs.zondax.ch/Zcash">Zondax&lt;/a> is ready
with code and integration PRs for shielded Zcash on Ledger hardware. Security review is
important at this early stage to ward off bugs that could put users&amp;rsquo; funds at
risk, so we&amp;rsquo;ll review their code and integrations next.&lt;/p>
&lt;h3 id="3-trezor-shielded">3. Trezor Shielded&lt;/h3>
&lt;p>I am also excited to audit &lt;a href="https://github.com/trezor/trezor-firmware/pull/2472">Trezor&amp;rsquo;s support for Zcash shielded
transactions&lt;/a>. Having the
two major hardware wallet vendors supporting shielded transactions will be a
major milestone for Zcash!&lt;/p>
&lt;h3 id="456-completing-a-round-of-wallet-audits">4,5,6. Completing a Round of Wallet Audits&lt;/h3>
&lt;p>In 2022, I began a series of wallet audits by reviewing &lt;a href="https://ywallet.app/">Ywallet&lt;/a> and
&lt;a href="https://github.com/adityapk00/zecwallet-light-cli">zecwallet-lite-cli&lt;/a>, two widely-used wallet codebases which had not received
recent review. Next up, I&amp;rsquo;ll complete the wallet audit series by auditing
&lt;a href="https://zecwallet.co/">ZecWallet-Lite&lt;/a>, &lt;a href="https://nighthawkwallet.com/">Nighthawk&lt;/a>, and the wallet in development by &lt;a href="https://github.com/zingolabs">ZingoLabs&lt;/a>.&lt;/p>
&lt;h3 id="7-zsas">7. ZSAs&lt;/h3>
&lt;p>Zcash Shielded Assets (ZSAs) are on the horizon for Zcash, with the &lt;a href="https://forum.zcashcommunity.com/t/a-proposal-for-shielded-assets-zsa-uda-for-defi-on-zcash/40520">design and implementation being provided by QEDIT&lt;/a>. Since ZSAs are a significant change to the Zcash protocol and its consensus rules, ZSAs should be included in the scope of the major audits of the network upgrade their implementation becomes a part of. It&amp;rsquo;s always better to have more eyes on the code, so I plan to audit ZSAs myself as well.&lt;/p>
&lt;h3 id="8-zephyr">8. Zephyr&lt;/h3>
&lt;p>&lt;a href="https://forum.zcashcommunity.com/t/project-zephyr-update-march22/41118">Zephyr&lt;/a>
is a project to build a metamask-like browser extension for Zcash. While the
project is still unfinished, I believe that support for Zcash in the browser is
on the critical path to adoption, so this is an important project to support.
Additionally, in-browser security models are complicated and error-prone, so it
will be worthwhile to take an early look.&lt;/p>
&lt;h3 id="9-live-infrastructure">9. Live Infrastructure&lt;/h3>
&lt;p>The Zcash ecosystem depends on live running infrastructure such as various
lightwalletd instances, the community forums, block explorers, and more. Zcash
users&amp;rsquo; security depends on the security of this infrastructure. Throughout the
year I will be offering security review and penetration tests to the maintainers
of this infrastructure.&lt;/p>
&lt;h3 id="9-other">9. Other&lt;/h3>
&lt;p>Several smaller-yet-popular projects like &lt;a href="https://free2z.cash/docs/">Free2z&lt;/a>
and &lt;a href="https://zecpages.com/z/all">ZECpages&lt;/a> are also deserving of security
review. Time permitting, I would like to perform some shorter audits of projects
like these alongside the longer audits listed above.&lt;/p>
&lt;p>If you don&amp;rsquo;t see your project on this list, but you feel like you could benefit
from an audit in 2023, please &lt;a href="https://zecsec.com/contact/">reach out&lt;/a> and I will do
my best to accommodate you!&lt;/p>
&lt;h2 id="security-side-projects">Security Side-Projects&lt;/h2>
&lt;p>In addition to security audits, there are a number of &amp;ldquo;side projects&amp;rdquo; I hope to
work on to support Zcash&amp;rsquo;s security.&lt;/p>
&lt;h3 id="office-hours-and-other-security-assistance-for-projects">Office Hours and Other Security Assistance for Projects&lt;/h3>
&lt;p>Anyone working in the Zcash ecosystem can now set up a private meeting with me
using &lt;a href="https://calendly.com/zecsec/zcash-security-meeting">my Calendly&lt;/a>.&lt;/p>
&lt;p>The kind of support projects can get this way includes:&lt;/p>
&lt;ul>
&lt;li>Getting early security feedback on designs and code.&lt;/li>
&lt;li>Help with responding to vulnerability reports.&lt;/li>
&lt;li>Incident response for attacks on infrastructure.&lt;/li>
&lt;li>Secure UX review of API designs and user interfaces.&lt;/li>
&lt;li>Getting answers to technical questions about the Zcash protocol.&lt;/li>
&lt;li>Anything else security- or -privacy-related, really!&lt;/li>
&lt;/ul>
&lt;p>In addition to supporting Zcash projects themselves, I will also be available
to the Zcash Grant Committee to support their decision-making by providing
technical or security-related input.&lt;/p>
&lt;h3 id="wallet-edge-cases">Wallet Edge Cases&lt;/h3>
&lt;p>A recommendation I&amp;rsquo;ve made in all of my wallet audits so far is to implement
better integration testing of wallets&amp;rsquo; state management in the face of edge
cases like reorgs, transactions failing to be mined, and other rare-but-possible
occurrences. Bugs in handling these kinds of edge cases could leave wallets in
invalid states, causing them to break or confuse users about how much funds they
have.&lt;/p>
&lt;p>The first step towards improving wallet testing is to enumerate all such edge
cases. With a complete list of edge cases, the quality of existing wallet tests
can be measured by determining which edge cases are covered and which are not.&lt;/p>
&lt;p>In 2023 I hope to release a nearly-complete edge case list, which can then be
used by wallet authors to improve their tests.&lt;/p>
&lt;h3 id="consensus-rule-labeling">Consensus Rule Labeling&lt;/h3>
&lt;p>A security engineer entering the Zcash ecosystem for the first time is faced
with the daunting task of &lt;em>finding&lt;/em> the code that implements Zcash&amp;rsquo;s consensus
rules. As a result, a large portion of audit time is used inefficiently, spent
finding and understanding consensus rule code.&lt;/p>
&lt;p>The efficiency of future consensus rule audits can be improved by labeling the
locations of all consensus rules in the code. Electric Coin Company has already
&lt;a href="https://github.com/zcash/zcash/pull/5912">started on this project&lt;/a>, and in 2023
I hope to advance it by labeling more consensus rules and &lt;a href="https://github.com/zcash/zcash/issues/6011">writing a linter for
the rule labeling format&lt;/a>.&lt;/p>
&lt;h3 id="secure-messaging-over-memos">Secure Messaging Over Memos&lt;/h3>
&lt;p>A popular use case for Zcash&amp;rsquo;s memo field is sending messages. However, Zcash&amp;rsquo;s
memo field currently lacks several properties that are required for secure
messaging. For example, it is not signed, so wallets cannot be sure of messages'
origins, and it is not forward-secure, so if keys are compromised all past
messages can be decrypted.&lt;/p>
&lt;p>In 2023, I hope to produce some design sketches that, if implemented, would make
it easier to build Signal-like secure messaging on top of Zcash. This project is
also a good candidate for a Zcash Community Grant RFP; I will be available to
assist the grant committee with writing up an RFP, if desired.&lt;/p>
&lt;h2 id="whats-left-out">What&amp;rsquo;s Left Out?&lt;/h2>
&lt;p>In my recently-published &lt;a href="https://zecsec.com/overview/">Zcash Ecosystem Security Overview&lt;/a> page, I laid out a list of big picture security and privacy
challenges for Zcash. The roadmap above touches on some of them, however there
are several that I &lt;em>probably won&amp;rsquo;t&lt;/em> have dedicated time for in 2023. They
deserve to be highlighted anyway:&lt;/p>
&lt;h3 id="scalable-privacy-for-wallets">Scalable Privacy for Wallets&lt;/h3>
&lt;p>A challenge faced by all cryptocurrencies that aim to offer strong, formal
privacy guarantees is: how can wallets&amp;rsquo; find their funds and make their funds
spendable quickly and efficiently?&lt;/p>
&lt;p>At present, Zcash uses &amp;ldquo;trial decryption&amp;rdquo;, where the wallet must try to decrypt
every transaction on the blockchain to find the ones that belong to it. There are many
alternatives to this design with varying levels of privacy and scalability.
I&amp;rsquo;ve surveyed them in my post, &lt;a href="https://zecsec.com/posts/scalable-private-money-needs-scalable-private-messaging/">Scalable Private Money Needs Scalable Anonymous Messaging&lt;/a>.&lt;/p>
&lt;h3 id="unintentional-andor-forced-use-of-transparent-transactions">Unintentional and/or Forced Use of Transparent Transactions&lt;/h3>
&lt;p>Usage of transparent transactions on the Zcash blockchain remains high.
Transparent addresses and transactions offer users the ability to transact
transparently, with consent, whenever they wish to do so. However, the high
transparent usage might be a sign that some users misunderstand the privacy
level provided by transparent transactions or that users are forced into making
parts of their transactions transparent, i.e. by third-parties who do not fully
support shielded addresses.&lt;/p>
&lt;p>I know of at least one anecdote where someone put themselves at risk by using a
transparent address, because they thought &amp;ldquo;Zcash is private.&amp;rdquo;&lt;/p>
&lt;p>In my view, this problem should be tackled with (a) research into how
frequently users misunderstand the privacy properties of using transparent
addresses, (b) UX design within wallets that communicates privacy levels clearly
and simply, (c) support requests from the community to third parties and extra
engineering effort to increase shielded adoption, (d) an eventual removal of
transparent addresses, replaced by the use of viewing keys.&lt;/p>
&lt;h3 id="mitigating-c-memory-corruption-bug-risk-in-zcashd">Mitigating C++ Memory Corruption Bug Risk in Zcashd&lt;/h3>
&lt;p>The main fullnode implementation of Zcash is written in C++, which puts it at
risk of entire classes of security vulnerabilities that cannot exist within
projects that are written in safer languages, like Rust. Deprecating the legacy
&lt;code>zcashd&lt;/code> codebase should be a priority, to be replaced by &lt;code>zebra&lt;/code>. These
risks could also be mitigated with better fuzzing of &lt;code>zcashd&lt;/code>&amp;rsquo;s code, but it&amp;rsquo;s
probably better to get rid of the C++ code entirely.&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>I&amp;rsquo;m looking forward to a productive year of security audits in 2023. Along with
the audits, I&amp;rsquo;m planning several side projects in support of Zcash&amp;rsquo;s security
like writing up better guidance for wallet testing, being more available to all
projects in office hours, working to label consensus rules, and exploring
improvements to the memo field for better secure messaging.&lt;/p>
&lt;p>Of course, all of these plans are subject to change in case new higher-priority
risks or projects appear, but this should give the community a good sense for
what to expect in the coming year.&lt;/p>
&lt;p>Let&amp;rsquo;s make the new year Zcash&amp;rsquo;s best year yet!&lt;/p></description><author>trandcanh@gmail.com (Calvin Tran)</author><guid>https://zecsec.com/posts/zecsec-roadmap-for-2023/</guid><pubDate>Tue, 03 Jan 2023 11:08:00 -0700</pubDate></item><item><title>YWallet Audit Results Published</title><link>https://zecsec.com/posts/ywallet-audit-published/</link><description>&lt;p>In October of last year, I reviewed &lt;a href="https://ywallet.app/">YWallet&lt;/a> for security
and privacy issues. This was the first audit I performed for the Zcash Ecosystem
Security grant.&lt;/p>
&lt;p>Today, the final report is being made available to the Zcash community at the
link below.&lt;/p>
&lt;p>The audit found one high-severity issue, two medium-severity issues, and several
low-severity issues. At this point in time, all issues have been remediated or
deemed to be safe to de-prioritize relative to other work.&lt;/p>
&lt;p>The high-severity issue was a problem with the way the wallet stored users'
contact lists in transaction memos. An attacker who knew a user&amp;rsquo;s address could
modify the user&amp;rsquo;s contact list by sending them specially-crafted memos. This
made it possible to carry out a man-in-the-middle between two users using
YWallet to chat with each other. The problem has been mitigated by only allowing
contact list updates from memos in transactions that were signed by the same
wallet. See the full report for details of the medium- and low-severity issues.&lt;/p>
&lt;p>The report highlights the general need for a memo signing standard as well as a
more-comprehensive suite of tests for Zcash wallets. These are priorities in my
&lt;a href="https://zecsec.com/posts/zecsec-roadmap-for-2023/">2023 roadmap&lt;/a>.&lt;/p>
&lt;p>Thanks to Ywallet&amp;rsquo;s author hanh for quick feedback on the report and fast bug fixes.&lt;/p>
&lt;p>&lt;a href="https://zecsec.com/audits/YWalletAuditReport-FINALv3.pdf">&lt;strong>YWallet Security and Privacy Analysis Report (PDF)&lt;/strong>&lt;/a>&lt;/p></description><author>trandcanh@gmail.com (Calvin Tran)</author><guid>https://zecsec.com/posts/ywallet-audit-published/</guid><pubDate>Tue, 03 Jan 2023 07:00:00 -0700</pubDate></item><item><title>Security Audit Process</title><link>https://zecsec.com/posts/security-audit-process/</link><description>&lt;p>In this post, I&amp;rsquo;m going to shed light on the process I follow to find bugs in my
audits of Zcash ecosystem software. Hopefully, this will be useful to you if you
are looking to understand more about how audits work or even learning how to
audit software yourself.&lt;/p>
&lt;p>The process I&amp;rsquo;m describing here should not be taken as gospel. Different
security auditors follow different processes, and I often deviate from this
process significantly to tailor my audits to the specific projects I am helping.&lt;/p>
&lt;h2 id="audit-process">Audit Process&lt;/h2>
&lt;h3 id="scoping-and-timeboxing">Scoping and Timeboxing&lt;/h3>
&lt;p>The first step in any audit is to understand &lt;em>what you&amp;rsquo;re auditing&lt;/em> and &lt;em>how
long you have to audit it&lt;/em>. This is crucial, because auditor-time is an
exceptionally rare resource, so it needs to be applied effectively and to the
right thing.&lt;/p>
&lt;p>In commercial engagements, the client and auditor often roughly agree on a
timeframe and budgeting (e.g. 2 weeks of auditing at $2,000 per auditor-day),
and have a back-and-forth discussion about the scope and sign mutual contracts
before the engagement begins. This is an inefficiency in the process that I
personally like to avoid, and thankfully past clients have trusted me to choose
my own scope, prioritizing what I feel is most important for the client. A
detailed scoping process makes sense whenever the client is already aware of
specific kinds of risks they need to mitigate, or if multiple auditors are being
hired to look at the same project and are to be tasked with different focus
areas.&lt;/p>
&lt;p>Out of this step in the process, you want to know how many days of paid time you
have, what general categories of bugs you&amp;rsquo;ll be looking for, and if anything is
off-limits (such as pen-testing production systems). You should also make it
clear up front whether or not the audit report will be published, as audit firms
are sometimes hesitant to do so, not wanting their report to be seen as a
&amp;ldquo;guarantee of security&amp;rdquo; or &amp;ldquo;stamp or approval&amp;rdquo;, and clients may not want their
mistakes to be publicized.&lt;/p>
&lt;h3 id="brainstorming--target-research">Brainstorming &amp;amp; Target Research&lt;/h3>
&lt;p>I see auditing as a creative process, so once any engagement begins, the first
thing I do is start brainstorming. Before I look at anything specific to the
target project, I think about what kind of project it is and try to enumerate
all the things that could possibly go wrong with &lt;em>that kind of thing&lt;/em>. For
example, if it&amp;rsquo;s an encryption program, I think about: weak key generation,
nonce reuse, weak encryption algorithms, lack of authentication, side-channel
attacks, and so on. I write all of these possibilities down. The point of this
exercise is to bring all of the things that &lt;em>might&lt;/em> go wrong into your
short-term memory so that they will stand out to you, if they actually &lt;em>have&lt;/em>
gone wrong, while you&amp;rsquo;re reading the relevant code.&lt;/p>
&lt;p>Next, I learn as much as I can about the target project without diving into
anything too technical. I read the docs, the changelog, issues that look
relevant to security on the issue tracker, google for past vulnerabilities, and
read any past audit reports of the project. I build and use the project, too. As
I am doing that, I keep expanding my brainstorm notes with new ideas that come to
mind.&lt;/p>
&lt;p>At the end of the brainstorming and research phase, you should have a list of
&lt;em>potential bugs&lt;/em> and &lt;em>attacker goals&lt;/em>. Your potential-bugs list is a brainstorm
that ideally includes all weaknesses that could possibly exist in the target
project (e.g. weak random number generator), and your attacker-goals list is a
brainstorm that ideally includes any goals an attacker might have (e.g. decrypt
the data).&lt;/p>
&lt;p>Your goal, during the audit, will be to find a set of weaknesses that an
attacker could exploit to accomplish their goal (e.g. the random number generator
produces weak keys, so an attacker can brute-force the key and decrypt the
data).&lt;/p>
&lt;h3 id="threat-modeling">Threat Modeling&lt;/h3>
&lt;p>At this point, you have a good understanding of what the target project is, what
weaknesses it might have, and the various ways attackers might try to attack its
users. If time permits, you can write up a formal (or at least detailed) threat
model for the project. If you do this right, it will help the developers
understand the security properties of their own software that they need to
maintain in the future, help users understand what security properties they&amp;rsquo;re
actually getting, and speed up future audits.&lt;/p>
&lt;p>There are many valid approaches to threat modeling, a common one is
&lt;a href="https://en.wikipedia.org/wiki/STRIDE_(security)">STRIDE&lt;/a>, however I prefer an
approach that I call &lt;a href="https://github.com/defuse/ictm">Invariant-Centric Threat
Modeling&lt;/a> which puts users first, requiring
security properties to be written in language that users can actually
understand, and considers it a &amp;ldquo;bug&amp;rdquo; if users ever think they are getting some
security property that they actually are not.&lt;/p>
&lt;h3 id="source-code-review">Source Code Review&lt;/h3>
&lt;p>Finally, the actual review process begins. I start by understanding the
directory structure of the project (the &lt;code>tree&lt;/code> command is very helpful!).
Then, I start reading code file-by-file. If there is an entrypoint to the
project (i.e. &lt;code>main())&lt;/code>), I will usually start there. But generally, I will
just read each file, in alphabetical order.&lt;/p>
&lt;p>You might be a little surprised by the fact I read the files in alphabetical
order. Wouldn&amp;rsquo;t it be better to &lt;em>understand&lt;/em> the program by tracing through call
stacks, understanding how classes relate to each other by drawing UML diagrams,
and so forth? In a time-crunched audit (as all audits are), this actually isn&amp;rsquo;t
the best use of time. It&amp;rsquo;s important to understand how the code you&amp;rsquo;re reading
fits in to the overall structure of the program, but if the code is well-written
and classes and functions are well-named, you can often correctly guess how it
fits in. In practice, I find most of my bugs in this linear scan of the code. A
linear scan of the code also guarantees a kind of completeness: you can be sure
that you&amp;rsquo;ve at least had your eyeballs pointed at every single line of code in
the project.&lt;/p>
&lt;p>For this to work, the brainstorming process mentioned above is essential.
Without it, problems won&amp;rsquo;t &amp;ldquo;jump out&amp;rdquo; at you as you are reading through the
code. It&amp;rsquo;s also important to &lt;em>continue&lt;/em> that same brainstorming process &lt;em>as&lt;/em> you
read the code, making note of any new ideas for potential problems that come to
mind as you are diving deeper into the code. Make notes, like &amp;ldquo;this function
returns -1 on error, if the caller doesn&amp;rsquo;t check it, a decryption error might be
unnoticed, is the caller actually checking it?&amp;rdquo;, instead of getting bogged down
confirming problems in this part of the process.&lt;/p>
&lt;p>After the first pass of source code review, you should have an expanded set of
notes with some potential issues, which you&amp;rsquo;ll want to check later. I use a star
system to help prioritize which possible problems are most-worth looking into
later, e.g. &amp;ldquo;*** it looks like it&amp;rsquo;s using &lt;code>rand()&lt;/code> to generate key!?&amp;rdquo;, &amp;ldquo;* make
sure the caller doesn&amp;rsquo;t pass a negative number here or else this will panic&amp;rdquo;.&lt;/p>
&lt;p>You should also be confused about a lot of things and have notes like &amp;ldquo;I don&amp;rsquo;t
get how this works!?&amp;rdquo;, &amp;ldquo;*** wtf how can this possibly be secure!!??&amp;rdquo;. In this stage,
we&amp;rsquo;ve been going for breadth and speed rather than depth and confirmation; this
is normal.&lt;/p>
&lt;p>This is a good point to pause and do even more brainstorming. Ask yourself &amp;ldquo;what
else could go wrong?&amp;rdquo;, &amp;ldquo;could any of the more-minor problems I&amp;rsquo;ve
identified be combined together to attack the system in bigger ways?&amp;rdquo;&lt;/p>
&lt;h3 id="check-priority-potential-issues">Check Priority Potential Issues&lt;/h3>
&lt;p>After reviewing most or all of the code, you should have a much better
understanding of how the code works, where things are, and a big list of TODOs:
possible problems and a bunch of things you&amp;rsquo;re really confused about. The next
step is to confirm some of those potential issues. This is the part where you
actually need to start tracing through call stacks, understanding classes'
relationships to each other, understanding if vulnerable-looking code is
actually something an attacker&amp;rsquo;s input can reach, and so on.&lt;/p>
&lt;p>If you&amp;rsquo;re really time-crunched, you won&amp;rsquo;t be able to check everything, so
prioritize by which problems you intuitively think are most likely to be &amp;ldquo;real&amp;rdquo;,
and by which kinds of problems would be the worst for the project&amp;rsquo;s users.&lt;/p>
&lt;p>A key thing to look for in this stage is the correctness (or incorrectness) of
how different components of the software interface with each other. This is
especially true when the different components were written by different people,
e.g. if your target software uses a library, you want to carefully read that
library&amp;rsquo;s documentation and make sure it&amp;rsquo;s being used correctly.&lt;/p>
&lt;p>At the end of this stage, you should have found the bulk of the issues which you
can begin writing up in your report.&lt;/p>
&lt;h3 id="deep-analysis-for-correctness">Deep Analysis for Correctness&lt;/h3>
&lt;p>Following the steps above will give you a broad and efficient coverage of the
entire project, and you will likely have found most of the bugs that will make
it into your report. For some kinds of code, it&amp;rsquo;s unavoidably necessary to dive
in much deeper and check that &lt;em>everything&lt;/em> is correct.&lt;/p>
&lt;p>&amp;ldquo;Correctness&amp;rdquo; means that the code always does what it is intended to, i.e. that
there are no bugs at all. As much as security engineers like to talk about
&amp;ldquo;security bugs&amp;rdquo; as a distinct category from &amp;ldquo;ordinary&amp;rdquo; kinds of bugs,
security is really about correctness. That&amp;rsquo;s because &lt;em>any&lt;/em> kind of bug, even
ones that seem benign, can potentially be used by an attacker to further their
goals.&lt;/p>
&lt;p>For certain kinds of code, especially cryptography, parsers, and anything
enforcing access control, there is no way to assure security except to deeply
understand and ensure the absolute correctness of all of the relevant code. The
modern way to do this is via formal verification, a computer-checkable proof
that the code will always do exactly what it is intended to do. Formal
verification is expensive to implement (but tools are getting better), and it
depends on having a detailed specification of what the code is &amp;ldquo;supposed to do&amp;rdquo;,
so it is not always a viable option.&lt;/p>
&lt;p>The next best thing is for a human&amp;mdash;the auditor&amp;mdash;to carefully check that
everything is correct. Based on the preceding stages, you should have a good
idea of which parts of the target program are ultra-security-critical and are
worthy of checking for correctness in extreme detail. The mindset to be in here
is that of someone trying to &lt;em>prove&lt;/em> the code is correct. Unless you are
absolutely, mathematically, convinced that the code is correct and conforms to
its specification, you still have more work to do.&lt;/p>
&lt;p>Doing this is extremely costly; whereas you might be able to get through a dozen
source code files in a day of normal review, it might take an entire day of
careful thinking to ensure the correctness of just one part of a cryptographic
algorithm or protocol.&lt;/p>
&lt;p>There are some tricks to avoid this, such as writing randomized tests to compare
two implementations of cryptographic primitives against each other, but to
whatever degree the relevant code is absolutely essential for security, you
often have to spend a lot of time checking its correctness.&lt;/p>
&lt;h3 id="the-writeup">The Writeup&lt;/h3>
&lt;p>At last, it&amp;rsquo;s time to write up the report. The format I like to use is:&lt;/p>
&lt;ol>
&lt;li>Introduction &amp;ndash; describe the audit scope and write up the threat model for the project (if they don&amp;rsquo;t already have one).&lt;/li>
&lt;li>Security &amp;amp; Privacy Findings &amp;ndash; list each issue that you&amp;rsquo;ve found, describing its severity and recommended prioritization, explaining it in detail, and recommend ways to fix it.&lt;/li>
&lt;li>Recommendations &amp;ndash; make suggestions to improve the overall quality of the code and/or speed up future audits.&lt;/li>
&lt;li>Good Things &amp;ndash; say genuine good things about the project/code, so that the report isn&amp;rsquo;t all negative.&lt;/li>
&lt;li>Future Work &amp;ndash; list the things you couldn&amp;rsquo;t cover in this audit, but should be covered by future audits. This section will be invaluable to future auditors.&lt;/li>
&lt;li>Conclusion &amp;ndash; summarize everything briefly.&lt;/li>
&lt;/ol>
&lt;h3 id="remediation--checking-the-fixes">Remediation &amp;amp; Checking the Fixes&lt;/h3>
&lt;p>It is common for fixes to reported security bugs to be incomplete or incorrect,
so it&amp;rsquo;s important to evaluate the fixes to the bugs you have reported. A really
common pattern is for developers to &amp;ldquo;block the exploit&amp;rdquo;, i.e. prevent one way of
exploiting the issue you described, without fixing the actual underlying
problem. I like to remain available to the developers of the projects I audit
until I&amp;rsquo;ve confirmed that all of the issues are fixed or we&amp;rsquo;ve mutually agreed a
fix is unnecessary or is safe to de-prioritize.&lt;/p>
&lt;h2 id="tooling--automation">Tooling &amp;amp; Automation&lt;/h2>
&lt;p>What I&amp;rsquo;ve described above is for a manual security review. Sometimes it&amp;rsquo;s
useful to use tools to assist with the audit process. However, I personally
haven&amp;rsquo;t found much success using security-specific tooling in my audits.
Anything an XSS or SQL injection scanner might find would definitely be found in
the manual review I would be doing anyway.&lt;/p>
&lt;p>There are some exceptions, where automation and tooling is really helpful:&lt;/p>
&lt;h3 id="unit-integration-and-regression-tests">Unit, Integration, and Regression Tests&lt;/h3>
&lt;p>A unit test or integration test of a software&amp;rsquo;s security property is worth a
thousand reviews, because it can be run automatically upon every change to the
software, perpetually ensuring that the property is satisfied.&lt;/p>
&lt;p>It might feel stupid, but make sure all the basic tests are in place, like &amp;ldquo;try
to decrypt the file with the wrong password&amp;rdquo; or &amp;ldquo;make the software connect to a
server with a self-signed certificate.&amp;rdquo; Even stupid tests will catch bugs
sometimes.&lt;/p>
&lt;p>Think about all the edge cases the target software might encounter, and
recommend that all of those edge cases be tested.&lt;/p>
&lt;p>Whenever a security bug is found, do the best you can to test for the presence
of that-or-similar bugs, so that if it ever gets re-introduced, it will be caught quickly.&lt;/p>
&lt;h3 id="dependency-update-checkers">Dependency Update Checkers&lt;/h3>
&lt;p>Tools like &lt;code>cargo audit&lt;/code>, &lt;code>./gradlew dependencyCheckAnalyze&lt;/code>, &lt;code>npm outdated&lt;/code> are invaluable for finding dependencies that are out of date or have
known vulnerabilities. These kinds of tools are available for most languages and
platforms, use them!&lt;/p>
&lt;h3 id="fuzzing">Fuzzing&lt;/h3>
&lt;p>Fuzzing is the process of using various types of algorithms to generate &amp;ldquo;random&amp;rdquo;
input to throw at your program to try to find bugs and crashes.
Counter-intuitively, fuzzing can be &lt;a href="https://lcamtuf.coredump.cx/afl/">incredibly successful at finding
bugs&lt;/a>, especially in projects written in
unsafe languages like C/C++.&lt;/p>
&lt;p>You can also &amp;ldquo;fuzz&amp;rdquo; implementations of cryptographic algorithms against each
other. If two implementations of a cipher or hash function, say, are supposed
to be equivalent, you can find differences between them by throwing the same
random data at both, as long as any &amp;ldquo;bug&amp;rdquo; occurs with a sufficiently high
probability.&lt;/p>
&lt;h2 id="to-write-exploits-or-not">To Write Exploits, or Not?&lt;/h2>
&lt;p>So far, I&amp;rsquo;ve written about how to find bugs, but what about exploiting them?
Exploitation is often the funnest part of security work, but it often isn&amp;rsquo;t
necessary. If the client understands the bug and is going to fix it, then it
usually isn&amp;rsquo;t worth the time to develop an exploit.&lt;/p>
&lt;p>The two exceptions are: (a) if the client doesn&amp;rsquo;t acknowledge the existence of a
bug and you need to prove it&amp;rsquo;s real, you need to write an exploit, and (b) if
you&amp;rsquo;ve got a severe bug on your hands, and you need to understand its
consequences or exploitability more-precisely, it can be beneficial to write an
exploit.&lt;/p>
&lt;p>I personally prefer to make false-positive errors in my security work than
false-negative errors. That is, if I&amp;rsquo;m unsure about the exploitability of a
given issue, I&amp;rsquo;ll include it in my report anyway, accepting a small chance that
I&amp;rsquo;m wrong. This saves the cost of rigorously proving the existence of the
problem, and makes sure that nothing that could be a real issue gets dropped.
The downside is that you might be embarrassed by reporting a bug that isn&amp;rsquo;t
real, but that&amp;rsquo;s better than the alternative.&lt;/p></description><author>trandcanh@gmail.com (Calvin Tran)</author><guid>https://zecsec.com/posts/security-audit-process/</guid><pubDate>Thu, 29 Dec 2022 07:00:00 -0700</pubDate></item><item><title>Scalable Private Money Needs Scalable Anonymous Messaging</title><link>https://zecsec.com/posts/scalable-private-money-needs-scalable-private-messaging/</link><description>&lt;p>In this post I’m going to argue that any scalable private Internet money system
will need to rely on an equally-scalable and equally-private anonymous messaging
system.&lt;/p>
&lt;p>Ultimately, I will argue that the best approach to scaling private money is to
&lt;em>directly and explicitly&lt;/em> build a scalable anonymous communication system,
rather than proceeding through a series of ad-hoc improvements to current
designs.&lt;/p>
&lt;h2 id="backstory">Backstory&lt;/h2>
&lt;p>The performance of Zcash mobile wallets has been degraded massively; this was
caused by a huge increase in private transaction load on the network. This
problem is not specific to Zcash—all private money systems aiming to offer
strong privacy guarantees will face this challenge eventually. To understand
why, we need to understand how the current best design for private Internet
money works.&lt;/p>
&lt;h2 id="protocol-recap">Protocol Recap&lt;/h2>
&lt;p>When Alice wants to send Bob a payment, Alice creates a &lt;em>note&lt;/em> containing the
value she wants to send to Bob. In her transaction, Alice posts three things to
the public blockchain: a note commitment, a zero-knowlege proof, and a note
ciphertext.&lt;/p>
&lt;p>The note commitment ties the newly-created note to Bob’s secret keys, so that
only Bob can spend the note. The zero-knowledge proof ensures that Alice is
creating the note honestly, i.e. she’s only creating it from money she controls,
and that she isn’t creating new money out of thin air.&lt;/p>
&lt;p>The third part, the note ciphertext, contains all of the information Bob
needs—along with his secret keys—to spend the value he has received from Alice.
A key-private encryption algorithm is used to create this ciphertext, which allows
Bob to decrypt it with his secret key, while ensuring nobody—even people who know
Bob’s address—can tell that the ciphertext belongs to Bob.&lt;/p>
&lt;h2 id="the-performance-bottleneck">The Performance Bottleneck&lt;/h2>
&lt;p>This design creates a scalability bottleneck: Bob has to try to decrypt every
ciphertext on the blockchain to find the notes that belong to him. When there
are a lot of new notes, his wallet will take a long time to get through them
all. In current implementations, it sometimes takes &lt;em>days&lt;/em> of trial-decrypting
to catch up with all of the transactions on the blockchain, depending on how far
behind the wallet is.&lt;/p>
&lt;p>This bottleneck isn’t all for nothing, it’s what gives the system its strong
privacy guarantees.&lt;/p>
&lt;p>The information Alice broadcasts in her transaction looks
like random noise, so although an attacker can tell &lt;em>that&lt;/em> Alice is sending a
transaction, the attacker can’t tell who it’s going to or what the amount is. On
Bob’s end, an attacker can tell &lt;em>that&lt;/em> Bob’s wallet has downloaded &lt;em>all
transactions in existence&lt;/em>, but the attacker cannot tell &lt;em>whether or not&lt;/em>, or
&lt;em>how many&lt;/em>, transactions Bob’s wallet actually received&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>This everyone-has-to-try-to-decrypt-everything bottleneck is inherent to all
private money designs that offer strong formal privacy guarantees. For these
systems to scale to thousands or millions of active users, trial decryption
needs to be replaced with something else.&lt;/p>
&lt;h2 id="private-money-implies-anonymous-messaging">Private Money Implies Anonymous Messaging&lt;/h2>
&lt;p>To overcome the trial-decryption bottleneck, Bob needs to be able to find out
about his notes—the money he is receiving—in an efficient way.&lt;/p>
&lt;p>We can show formally that solving this problem is closely related to a different
computer science problem: that of building an anonymous messaging system (also
known in the literature as an “anonymous communication network”).&lt;/p>
&lt;p>To see why, we can reduce the problem of building an anonymous messaging system
to the problem of building a private money system. That’s computer-science speak
for using the solution to Problem A (building a private money system) to
construct a solution for Problem B (building an anonymous messaging system);
doing so shows that Problem A is at least as hard as Problem B, i.e. to do A you
must do B. To build private money you must build anonymous communication.&lt;/p>
&lt;p>Given a private money system, any two users of the system can use it to message
each other privately and anonymously with the same privacy and anonymity
properties as the underlying private money system. They can do this by encoding
their messages into transaction values. If Alice wants to say “Hello” to Bob,
she can encode her message to the ASCII values 72, 101, 108, 108, 111 and send a
series of transactions with values 0.0072, 0.0101, 0.0108, 0.0108, 0.0111, plus
some zero-valued transactions to hide the length of the message. Simple, right?
Any private money system can be used as an anonymous communication system with
only a constant-factor performance overhead.&lt;/p>
&lt;p>What this means is that in order to build a private money system with certain
formal privacy and scalability properties, we are &lt;em>logically required&lt;/em> to build
an anonymous messaging system with at least those same privacy and scalability
properties. It also means that research on the trade-offs and limitations of
anonymous messaging systems apply to private money systems as well.&lt;/p>
&lt;p>In the other direction, we can &lt;em>use&lt;/em> a scalable anonymous messaging system to
overcome the trial-decryption bottleneck of our current private money designs.
Using the anonymous messaging system, Alice can send Bob the ciphertext directly
so that Bob doesn’t have to try to decrypt everything. When we do this, the
privacy and scalability properties of the resulting private money system are
&lt;em>limited&lt;/em> by the privacy and scalability properties of the anonymous
communication system.&lt;/p>
&lt;h2 id="what-are-our-options">What are our options?&lt;/h2>
&lt;p>Let’s look at a few of the options we have for replacing trial decryption.
There’s &lt;em>tons&lt;/em> of research on anonymous messaging systems, so I’m going to
restrict my attention here to options that are already on private-money
projects’ roadmaps or that seem promising to me.&lt;/p>
&lt;h3 id="smarter-scanning">Smarter Scanning&lt;/h3>
&lt;p>The option currently being pursued in Zcash is smarter scanning algorithms.
These algorithms must still eventually try to decrypt every ciphertext, but they
can find some of a user’s funds earlier, so that the user has some spendable
money and can make payments faster, without waiting for the entire scan to
complete. It won’t eliminate the long scanning times, but it will make user
experience significantly better.&lt;/p>
&lt;p>For more details, see
&lt;a href="https://hackmd.io/@str4d/dagsync-graph-aware-zcash-wallets">https://hackmd.io/@str4d/dagsync-graph-aware-zcash-wallets&lt;/a>.&lt;/p>
&lt;p>This is a good stopgap measure in the face of bricked wallets, but in the long
term, we will need something more.&lt;/p>
&lt;h3 id="scanning-in-the-cloud">Scanning in the Cloud&lt;/h3>
&lt;p>Another simple approach is to retain the trial-decryption paradigm, but move it
out of the smartphone and into the cloud, on beefier computers.&lt;/p>
&lt;p>This would retain all of the on-chain privacy properties of current protocol
designs, since there are no changes to the data stored on-chain. However, users’
wallets would need to send their decryption keys to the cloud. The user’s
privacy will only be as strong as the security of those cloud computers. (Note
that this can be done without giving &lt;em>spend authority&lt;/em> to the cloud servers, so
users&amp;rsquo; funds are safe.)&lt;/p>
&lt;p>If many users share the same cloud computer for scanning, that cloud computer
becomes an attractive target for adversaries who want to de-anonymize a mass of
users. That risk can be reduced somewhat by giving each wallet its own isolated
computer in the cloud, but this increases the cost and setup complexity for
users, and doesn’t isolate users against the mass-exploitation of a common bug
in the cloud setup.&lt;/p>
&lt;p>Users’ privacy can be protected further at the cost of increasing CPU load on
the servers with homomorphic-encryption-based &lt;a href="https://forum.zcashcommunity.com/t/oblivious-message-retrieval/40715">Oblivious Message Retrieval
(OMR)&lt;/a>.&lt;/p>
&lt;p>Cloud scanning is not a good long-term solution because it does not
fundamentally improve the system’s scalability, it just moves it to faster CPUs
(and perhaps later onto cloud GPUs). With enough usage, even scanning in the
cloud will not be fast enough, and will be too costly.&lt;/p>
&lt;h3 id="fuzzy-message-detection--other-decoy-systems">Fuzzy Message Detection (&amp;amp; Other Decoy Systems)&lt;/h3>
&lt;p>&lt;a href="https://eprint.iacr.org/2021/089">Fuzzy Message Detection&lt;/a> (FMD) is an
intermediate approach between all-on-the-device scanning and all-in-the-cloud
scanning.&lt;/p>
&lt;p>With FMD, the transaction recipient (or the consensus rules in
&lt;a href="https://protocol.penumbra.zone/main/crypto/fmd/sender-receiver.html">Penumbra’s
case&lt;/a>)
selects a false-positive rate and generates a detection key which is sent to the
cloud server. The cloud server uses the detection key to find all of the user’s
transactions, plus a collection of false positives at the chosen rate. The
server cannot tell which transactions legitimately belong to the user or are
false positives, so some uncertainty is created about which transactions belong
to the wallet.&lt;/p>
&lt;p>For a false positive rate P ∈ [0, 1], this reduces the amount of transactions
the wallet needs to scan locally by a factor of P. For example, a 1%
false-positive rate would make the wallet’s scanning 100x faster at the privacy
cost of giving the server a list of 99% of all transactions which &lt;em>definitely do
not&lt;/em> belong to the wallet.&lt;/p>
&lt;p>Unfortunately, we need to be skeptical of FMD’s privacy guarantees.&lt;/p>
&lt;p>The most pressing problem occurs when Alice sends transactions to Bob
repeatedly. An adversary who compromised the FMD server can collect strong
statistical evidence that Alice is paying Bob. For example, suppose that Alice
sends 100 transactions to Bob and the adversary knows all of those transactions
were created by Alice. Even for false-positive rates higher than 50% (less than
2x speedup), if &lt;em>none&lt;/em> of those transactions were going to Bob, the chance that
&lt;em>all&lt;/em> of them would be downloaded by Bob (as false positives) is less than 1 in
2^100. So, if the adversary sees Bob download them all, they can be nearly
certain Alice is sending payments to Bob, and privacy has been broken.&lt;/p>
&lt;p>This particular attack can be mitigated with sender-side anonymity protections,
removing the assumption that the adversary knows Alice created the transactions.
However, other desirable privacy properties remain broken. For example, if the
adversary wants to find out which wallet owns a particular address, they can
send that address 100 transactions and then observe which wallet retrieves all 100
of them.&lt;/p>
&lt;p>These attacks are symptoms of a more fundamental problem with FMD, which is that
decoy-based systems are incapable of ensuring formal privacy guarantees.&lt;/p>
&lt;p>In &lt;a href="https://arxiv.org/abs/1812.05638">On Privacy Notions in Anonymous
Communication&lt;/a>, the authors survey and
systematize desirable formal privacy notions for anonymous messaging. The
authors worked out the logical implications between all of the formal notions in
their systematization. They found that all of them imply a notion called
“sender-receiver pair unlinkability”. That means that if a system doesn’t have
sender-receiver pair unlinkability, it doesn’t have any of the other formal
privacy notions that they considered.&lt;/p>
&lt;p>A simplified version of sender-receiver unlinkability is defined by a game. In
the game, a secret bit is chosen at random. If the bit is 0, Sender 1 sends a
message to Receiver 1 and Sender 2 sends a message to Receiver 2. If the secret
bit is 1, the destinations are swapped; Sender 1 sends to Receiver 2 and Sender
2 sends to Receiver 1. To win the game, i.e. to break the privacy property, the
adversary has to guess the secret bit.&lt;/p>
&lt;p>With FMD in this four-user scenario, either the false-positive rate is high
enough that both receivers download both senders’ messages (meaning no
efficiency has been gained), or one receiver fails to download one of the
sender’s messages. Since there are no false-negatives in FMD, this means that
the not-downloaded sender’s message was definitely not directed at that
receiver, and the adversary learns the secret bit. For example, if Receiver 1
&lt;em>didn’t&lt;/em> download Sender 1’s message, then we know the bit is 1, since if it was
0, Receiver 1 would have definitely downloaded Sender 1’s message.&lt;/p>
&lt;p>This shows that FMD cannot satisfy sender-receiver pair unlinkability, and by
the logical implications given in the paper, cannot satisfy any of the other
formal privacy definitions. FMD’s privacy guarantees are necessarily heuristic
and statistical.&lt;/p>
&lt;p>More analysis of FMD’s privacy properties against weaker privacy notions can be
found in &lt;a href="https://arxiv.org/abs/2109.06576">The Effect of False Positives: Why Fuzzy Message Detection Leads to
Fuzzy Privacy Guarantees&lt;/a>.&lt;/p>
&lt;p>In addition to lackluster privacy properties, FMD is also not scalable. The FMD
server must still process all transactions for each user, and at best it offers
a constant factor reduction in the scanning work that wallets must perform
locally.&lt;/p>
&lt;h3 id="using-existing-communication-channels">Using Existing Communication Channels&lt;/h3>
&lt;p>If two users already talk to each other over an existing secure messaging
system, then they can send transactions over the messenger. For those
transactions (but not others), the recipient’s wallet can avoid
trial-decryption. This is the idea behind &lt;a href="https://github.com/zcash/zips/pull/420">liberated
payments&lt;/a>.&lt;/p>
&lt;p>This scales well, but has two drawbacks.&lt;/p>
&lt;p>First, the user experience is a significant departure from what is common among
cryptocurrencies. Users are accustomed to sending money to an address given to
them by their counterparty; with liberated payments, they would have to add
their counterparty as a contact on a messenger and get their wallet to send them
a message. I believe this can be made usable, but the sheer fact it works
differently might be enough to put a lot of users off.&lt;/p>
&lt;p>Second, the privacy properties of the resulting system are only as good as the
metadata-resistance privacy properties of the messengers used. For example, if a
transaction is sent through a messenger that uses strong encryption, but the
messenger leaks metadata about message size (identifying the message as likely
being a liberated payment) and who the message is coming from and going to, an
adversary watching this metadata can tell approximately who is sending payments
to who, breaking privacy guarantees that users expect.&lt;/p>
&lt;p>Liberated payments would work great for use cases where users are making
payments to a website, for example sending funds to an exchange, buying
something from an online store, or donating to a charity. In this case, any
attackers monitoring the user&amp;rsquo;s Internet connection are already aware that there
is some kind of relationship between the user and the website they have visited.
If the payment information is sent through the same encrypted connection that
the user&amp;rsquo;s browser is already using to communicate with the website, the fact a
payment is being made can be kept secret. If the payment information is sent
through a separate connection (e.g. from the user&amp;rsquo;s smartphone wallet, with the
payment being made by scanning a QR code in a desktop browser), the fact a
payment was made will be leaked, but this might not matter for some use cases,
like if the website is a store and the attacker is already pretty sure that the
user is going to buy something.&lt;/p>
&lt;p>So, liberated payments would work well as a workaround to wallet performance
problems for payments to websites and for a subset of users who already have a
private means to communicate with each other, but it may not be a good long-term
solution because of the metadata-privacy weaknesses in existing private
messengers and because it requires users to learn a new UX.&lt;/p>
&lt;h3 id="sgx-based-approaches">SGX-based Approaches&lt;/h3>
&lt;p>Another way to scale would be to use a trusted, private server. Using an actual
trusted server would defeat the purpose of building a private money system (we’d
just be building another PayPal), but Intel’s SGX technology aims to make it
possible to approximate a trusted server in an untrusted way. This is the
approach that &lt;a href="https://mobilecoin.com/">MobileCoin&lt;/a> takes (in combination with
the decoy-based CryptoNote protocol).&lt;/p>
&lt;p>Unfortunately, SGX’s security has been broken repeatedly by side-channel attacks
against the processor
(&lt;a href="https://www.usenix.org/conference/usenixsecurity18/presentation/bulck">some&lt;/a>
&lt;a href="https://sgaxe.com/">recent&lt;/a>
&lt;a href="https://ieeexplore.ieee.org/abstract/document/9152636">examples&lt;/a>). Like
copy-protection (“DRM”), what SGX is trying to do is fundamentally impossible.
The CPU itself needs access to the private bits in order to compute on them, so
it can &lt;em>only&lt;/em> be a matter of &lt;em>how hard&lt;/em> it is for an attacker to access those
bits, and how much resources they need to expend to do so. It is conceivable
that one day SGX will attain a state where all known attacks are practically
infeasible, but that’s currently not the case, and we don’t know when (if ever)
that will happen. The &lt;em>variety&lt;/em> of methods that have recently been used to break
SGX and alternatives like ARM TrustZone is good evidence that there are still
more vulnerabilities waiting to be found, so we should expect researchers to
develop more attacks in the coming years.&lt;/p>
&lt;p>In my opinion, the best way to think about SGX’s security is: “If the system’s
operators are mostly honest and aren’t too well-resourced, then you’re safe, but
if the NSA breaks in, or anyone with serious resources wants to break the
system, SGX will fail.” This is not a good long-term solution, at least not
until SGX or an equivalent technology has proven itself to resist all kinds of
attacks for a number of years.&lt;/p>
&lt;h3 id="tor">Tor&lt;/h3>
&lt;p>Tor is by far the most widely-used anonymous communication system in existence
today. Its focus is on providing low-latency connections at the expense of
formal privacy guarantees.&lt;/p>
&lt;p>Tor works by having the client select three “nodes” from the pool of available
nodes: an entry node, a relay node, and an exit node. The client encrypts its
message to the exit node’s key, encrypts that ciphertext to the relay node’s
key, and encrypts that ciphertext to the entry node’s key. The entry node can
decrypt the first layer of encryption and forward it onto the relay node, who
can decrypt one step further and forward it onto the exit node, who decrypts the
last layer and sends the data to the intended destination. The entry node knows
who the user is, the exit node knows where the traffic is going, and the relay
node prevents the entry and exit nodes from finding each other and colluding to
see who’s-sending-what-to-who. Tor also supports onion services, which allow the
service being connected-to to remain anonymous as well.&lt;/p>
&lt;p>Tor can be used to build anonymous messaging, a notable example being
&lt;a href="https://cwtch.im/">Cwtch&lt;/a>. In this way, it could be used to build an anonymous
messaging system in support of private money.&lt;/p>
&lt;p>However, Tor’s design explicitly trades-off worse privacy guarantees in order to
have lower latency. This is necessary for it to be suitable for browsing web
pages. But the low latency makes it vulnerable to timing attacks: after a client
sends a packet, it will shortly thereafter show up at its destination. If an
adversary is situated close to the client user (e.g. at an ISP), and also close
to the destination server (e.g. at an Amazon datacenter), they can collect
enough packet-timing information to statistically infer who’s talking to who. It
is well-known and accepted that Tor’s anonymity can be broken by global passive
adversaries, and adversaries situated at both endpoints, using attacks like
this. A &lt;a href="https://ieeexplore.ieee.org/abstract/document/9471821">recent paper&lt;/a>
surveys different kinds of de-anonymization attacks on Tor.&lt;/p>
&lt;p>Tor’s privacy properties are heuristic and are weaker than those that come
standard with projects like Zcash&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>; they are certainly insufficient for some use
cases of private Internet money. Therefore, extreme care needs to be taken with
any attempt to solve payment scalability problems with Tor. We must be mindful
that relying on Tor will mean giving up on formal privacy guarantees and will
make the system vulnerable to global passive adversaries, as well as adversaries
that are capable of monitoring the traffic of the set of wallets they are
interested in.&lt;/p>
&lt;h3 id="mixnets">Mixnets&lt;/h3>
&lt;p>As argued by the reduction given above, a private money system fundamentally
&lt;em>is&lt;/em> an anonymous messaging system. It therefore makes sense to look towards the
best designs for anonymous communication systems in the literature if we want to
solve private money systems’ scalability problems.&lt;/p>
&lt;p>This could be termed the “embrace the real problem” approach. Rather than
working through a series of ad-hoc strategies to scaling private money, all of
which come with their own scalability bottlenecks and privacy weaknesses, it
would be a more effective use of resources to work directly on solving the
&lt;em>necessary&lt;/em> problem of scaling anonymous communication.&lt;/p>
&lt;p>State-of-the-art designs for scalable anonymous messaging use mixnets. Mixnets
work by collecting users’ messages into batches and using a series of “mixnodes”
to shuffle the messages before delivering them to recipients’ mailboxes. By
shuffling messages in large batches (requiring high latency), and by using
sufficient chaff traffic, mixnets can provide provable privacy guarantees.&lt;/p>
&lt;p>Mixnets are not a panacea, however. Fundamental trade-offs apply, such as
between their privacy properties, latency of messages, efficiency, and offline
message availability. They are a newer technology, too, which hasn’t seen much
proven deployment in practice (&lt;a href="https://nymtech.net/">Nym&lt;/a> is one example).&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>In this post I’ve surveyed different approaches to solving private money
systems’ scalability problems. I&amp;rsquo;ve included those that I consider plausibly
viable as well as those on existing projects&amp;rsquo; roadmaps. A common theme among
many of them is that they are not asymptotic scaling solutions, only making
constant-factor improvements or moving the processing to faster computers. Most
of them don’t offer formal privacy guarantees or, worse, have known attacks that
make them unsuitable for Internet money. Others, like mixnets, are expensive and
risky to implement. There is no clear winner.&lt;/p>
&lt;p>What &lt;em>is&lt;/em> clear, though, is that scaling private payments &lt;em>is&lt;/em> scaling anonymous
messaging.&lt;/p>
&lt;p>We should therefore turn our attention toward the best designs available in the
scientific literature on anonymous communication, which in my view is currently
mixnet research.&lt;/p>
&lt;p>It’s unlikely that we will find an off-the-shelf solution, ready to be
implemented, that will solve all of our problems. We will need to make
significant investments in anonymous communication science and engineering over
the long term to make private money work. This is worth doing, because this way,
we are embracing the real, unavoidable, problem that lies ahead of us.&lt;/p>
&lt;p>(Some updates to this article were made on 2023-02-16.)&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>Note that current implementations of Zcash light wallets don’t take advantage
of these strong privacy properties, because Bob’s wallet will fetch extra
details of just those transactions that belong to him for the sake of bandwidth
savings. See the &lt;a href="https://zcash.readthedocs.io/en/latest/rtd_pages/wallet_threat_model.html">Zcash Wallet App Threat
Model&lt;/a>
for more details.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>At least using the full-node implementation.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description><author>trandcanh@gmail.com (Calvin Tran)</author><guid>https://zecsec.com/posts/scalable-private-money-needs-scalable-private-messaging/</guid><pubDate>Tue, 15 Nov 2022 19:00:00 -0700</pubDate></item><item><title>October Update: Ywallet audited, and what's next?</title><link>https://zecsec.com/posts/october-update/</link><description>&lt;p>Hi Zcash fans! It&amp;rsquo;s time for the first monthly update on the Zcash Ecosystem
Security grant. This October, we saw the completion of a full security audit of
&lt;a href="https://ywallet.app/">Ywallet&lt;/a>.&lt;/p>
&lt;p>Ywallet&amp;rsquo;s fast scanning algorithm makes it an attractive option for users facing
long delays due to the recent high usage of the Zcash blockchain. It had also
received the least security review among the Zcash wallets, so we
decided to prioritize it as the first project to be audited for this grant.&lt;/p>
&lt;p>The audit report was delivered to Ywallet&amp;rsquo;s developers today and it will be
published for the community to see after all necessary issues have been
appropriately remediated.&lt;/p>
&lt;h2 id="whats-next">What&amp;rsquo;s next?&lt;/h2>
&lt;p>In November, we will continue the focus on wallets, this time reviewing
&lt;a href="https://github.com/adityapk00/zecwallet-light-cli">zecwallet-lite-cli&lt;/a>. This
library and command-line tool is the basis of the popular ZecWallet-lite wallet.&lt;/p>
&lt;p>After this, we plan to take a short detour to focus on some of the smaller and
earlier-stage community projects, before putting our focus back on wallets to
review ZecWallet-lite proper, Nighthawk, and others.&lt;/p>
&lt;p>If you&amp;rsquo;d like your project to be included in our upcoming audit schedule, please
shoot an email to &lt;a href="mailto:zecsec@defuse.ca">zecsec@defuse.ca&lt;/a> with a link to your source code repository.&lt;/p></description><author>trandcanh@gmail.com (Calvin Tran)</author><guid>https://zecsec.com/posts/october-update/</guid><pubDate>Fri, 28 Oct 2022 08:13:14 -0700</pubDate></item><item><title>Hello, World!</title><link>https://zecsec.com/posts/my-first-post/</link><description>&lt;p>Hi!&lt;/p>
&lt;p>This is where I will be posting be posting updates on the &lt;a href="https://forum.zcashcommunity.com/t/zcash-ecosystem-security-lead/42090">Zcash Ecosystem
Security&lt;/a>
grant project!&lt;/p></description><author>trandcanh@gmail.com (Calvin Tran)</author><guid>https://zecsec.com/posts/my-first-post/</guid><pubDate>Thu, 13 Oct 2022 08:22:29 -0600</pubDate></item></channel></rss>