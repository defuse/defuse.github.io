<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ZecSec: Zcash Ecosystem Security</title><description>Zcash Ecosystem Security Support</description><link>https://zecsec.com/</link><language>en</language><copyright>Copyright 272727, Calvin Tran</copyright><lastBuildDate>Thu, 23 Feb 2023 19:00:00 -0700</lastBuildDate><generator>Hugo - gohugo.io</generator><docs>http://cyber.harvard.edu/rss/rss.html</docs><atom:link href="https://zecsec.com//atom.xml" rel="self" type="application/atom+xml"/><item><title>ZecSec's Q4 2022 Transparency Report</title><link>https://zecsec.com/posts/2022-q4-transparency-report/</link><description>&lt;p>In order to ensure accountability and to help the Zcash community understand how
its funds are being spent, the ZecSec project will be posting quarterly
transparency reports.&lt;/p>
&lt;p>Note that some of these reports may be delayed, and some information may be
redacted, in order to prevent the disclosure of unresolved security bugs.&lt;/p>
&lt;p>The currently-approved
&lt;a href="https://forum.zcashcommunity.com/t/zcash-ecosystem-security-lead/42090">grant&lt;/a>
allows me to bill $1000 USD per day, up to a maximum of $17,000 per month, up to
12 total months. The sections below break down and explain my invoices for Q4
2022.&lt;/p>
&lt;h2 id="september--october">September &amp;amp; October&lt;/h2>
&lt;p>In September and October my focus was on auditing Ywallet. Ywallet was a
priority because it had not yet received any security review and it was one of
the only wallets that functioned in the face of the high transaction load
problem. The report from this audit is available &lt;a href="https://zecsec.com/posts/ywallet-audit-published/">here&lt;/a>.&lt;/p>
&lt;table class="table table-striped table-bordered">
&lt;thead>
&lt;tr>
&lt;th>Days&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>Setting up build environments, skimming over grants/projects, staying up to date on the forums.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>Reviewing various Zcash wallets for a potential DoS bug reported by ZingoLabs.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>8&lt;/td>
&lt;td>Auditing Ywallet&amp;rsquo;s zcash-sync library.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>5&lt;/td>
&lt;td>Auditing Ywallet itself.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>Delivering the Ywallet audit report and answering questions.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>0.5&lt;/td>
&lt;td>Setting up this website.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>0.5&lt;/td>
&lt;td>Reviewing ZIP 317 for security and privacy.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Total days: 17, Total paid: $17,000.&lt;/p>
&lt;h2 id="november">November&lt;/h2>
&lt;p>In November, I audited zecwallet-lite-cli, the transaction processing library
used by ZecWallet-Lite. This paves the way for a future audit of ZecWallet-Lite
itself. I also looked at the customizations that were made to the version of
lightwalletd that ZecWallet-Lite uses.&lt;/p>
&lt;table class="table table-striped table-bordered">
&lt;thead>
&lt;tr>
&lt;th>Days&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>Catching up on forums, planning, setting up Calendly for office hours.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>8&lt;/td>
&lt;td>Auditing zecwallet-lite-cli.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>Reviewing changes to lightwalletd in aditapk00/lightwalletd.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>Helping debug zcashd v5.3.0 build issues and getting the Arch Linux package maintainer to update the package.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>0.5&lt;/td>
&lt;td>Writing &lt;a href="https://zecsec.com/posts/scalable-private-money-needs-scalable-private-messaging/">Scalable Private Money Needs Scalable Anonymous Messaging&lt;/a>.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Total days: 11.5, Total paid: $11,500.&lt;/p>
&lt;h2 id="december">December&lt;/h2>
&lt;p>In December, I focused on planning for the new year. I quickly surveyed every
Zcash-related project that I could find and collected a list of past security
audits, research, and notable bugs. I published the first edition of the &lt;a href="https://zecsec.com/overview/">Zcash Ecosystem Security Overview&lt;/a> and a tentative &lt;a href="https://zecsec.com/posts/zecsec-roadmap-for-2023/">roadmap for 2023&lt;/a>.&lt;/p>
&lt;table class="table table-striped table-bordered">
&lt;thead>
&lt;tr>
&lt;th>Days&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>8&lt;/td>
&lt;td>Surveying all Zcash-related projects, preparing the ecosystem security overview and roadmap.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2&lt;/td>
&lt;td>Checking the Ywallet bug fixes and publishing the Ywallet audit report.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Total days: 10, Total paid: $10,000.&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>In Q4 of 2022, I completed two major audits of Ywallet and zecwallet-lite-cli. I
also contributed to a number of other security efforts such as performing
shorter security reviews of various projects, helping to investigate bugs,
collecting past security research, and writing up my research into options for
privately scaling Zcash.&lt;/p>
&lt;p>In total, I invoiced for 38.5 days and was paid $38,500 in ZEC.&lt;/p>
&lt;p>If you have questions about the work that was done or have suggestions for
future priorities, you can either email me at &lt;a href="mailto:zecsec@defuse.ca">zecsec@defuse.ca&lt;/a> or ask on &lt;a href="https://forum.zcashcommunity.com/t/zcash-ecosystem-security-lead/42090">the
grant&amp;rsquo;s forum
thread&lt;/a>.&lt;/p></description><author>trandcanh@gmail.com (Calvin Tran)</author><guid>https://zecsec.com/posts/2022-q4-transparency-report/</guid><pubDate>Fri, 27 Jan 2023 01:00:00 -0700</pubDate></item><item><title>ZecSec Roadmap for 2023</title><link>https://zecsec.com/posts/zecsec-roadmap-for-2023/</link><description>&lt;p>Happy New Year Zcash!&lt;/p>
&lt;p>For me, the days leading up to the new year are always a time of reflection and
planning. In that spirit, I&amp;rsquo;ve laid out a tentative roadmap for the ZecSec
project in 2023.&lt;/p>
&lt;h2 id="upcoming-audits">Upcoming Audits&lt;/h2>
&lt;h3 id="1-lightwalletd">1. Lightwalletd&lt;/h3>
&lt;p>All Zcash light wallets rely on the
&lt;a href="https://github.com/zcash/lightwalletd">lightwalletd&lt;/a> project to obtain
transaction information and to broadcast transactions to the network. Despite
its central importance to the Zcash ecosystem, it has never been subjected to a
third-party audit. I&amp;rsquo;ll begin the year with a thorough security review of its
entire codebase.&lt;/p>
&lt;h3 id="2-zondax">2. Zondax&lt;/h3>
&lt;p>Shielded hardware wallets have been a long time coming. Now, &lt;a href="https://docs.zondax.ch/Zcash">Zondax&lt;/a> is ready
with code and integration PRs for shielded Zcash on Ledger hardware. Security review is
important at this early stage to ward off bugs that could put users&amp;rsquo; funds at
risk, so we&amp;rsquo;ll review their code and integrations next.&lt;/p>
&lt;h3 id="3-trezor-shielded">3. Trezor Shielded&lt;/h3>
&lt;p>I am also excited to audit &lt;a href="https://github.com/trezor/trezor-firmware/pull/2472">Trezor&amp;rsquo;s support for Zcash shielded
transactions&lt;/a>. Having the
two major hardware wallet vendors supporting shielded transactions will be a
major milestone for Zcash!&lt;/p>
&lt;h3 id="456-completing-a-round-of-wallet-audits">4,5,6. Completing a Round of Wallet Audits&lt;/h3>
&lt;p>In 2022, I began a series of wallet audits by reviewing &lt;a href="https://ywallet.app/">Ywallet&lt;/a> and
&lt;a href="https://github.com/adityapk00/zecwallet-light-cli">zecwallet-lite-cli&lt;/a>, two widely-used wallet codebases which had not received
recent review. Next up, I&amp;rsquo;ll complete the wallet audit series by auditing
&lt;a href="https://zecwallet.co/">ZecWallet-Lite&lt;/a>, &lt;a href="https://nighthawkwallet.com/">Nighthawk&lt;/a>, and the wallet in development by &lt;a href="https://github.com/zingolabs">ZingoLabs&lt;/a>.&lt;/p>
&lt;h3 id="7-zsas">7. ZSAs&lt;/h3>
&lt;p>Zcash Shielded Assets (ZSAs) are on the horizon for Zcash, with the &lt;a href="https://forum.zcashcommunity.com/t/a-proposal-for-shielded-assets-zsa-uda-for-defi-on-zcash/40520">design and implementation being provided by QEDIT&lt;/a>. Since ZSAs are a significant change to the Zcash protocol and its consensus rules, ZSAs should be included in the scope of the major audits of the network upgrade their implementation becomes a part of. It&amp;rsquo;s always better to have more eyes on the code, so I plan to audit ZSAs myself as well.&lt;/p>
&lt;h3 id="8-zephyr">8. Zephyr&lt;/h3>
&lt;p>&lt;a href="https://forum.zcashcommunity.com/t/project-zephyr-update-march22/41118">Zephyr&lt;/a>
is a project to build a metamask-like browser extension for Zcash. While the
project is still unfinished, I believe that support for Zcash in the browser is
on the critical path to adoption, so this is an important project to support.
Additionally, in-browser security models are complicated and error-prone, so it
will be worthwhile to take an early look.&lt;/p>
&lt;h3 id="9-live-infrastructure">9. Live Infrastructure&lt;/h3>
&lt;p>The Zcash ecosystem depends on live running infrastructure such as various
lightwalletd instances, the community forums, block explorers, and more. Zcash
users&amp;rsquo; security depends on the security of this infrastructure. Throughout the
year I will be offering security review and penetration tests to the maintainers
of this infrastructure.&lt;/p>
&lt;h3 id="9-other">9. Other&lt;/h3>
&lt;p>Several smaller-yet-popular projects like &lt;a href="https://free2z.cash/docs/">Free2z&lt;/a>
and &lt;a href="https://zecpages.com/z/all">ZECpages&lt;/a> are also deserving of security
review. Time permitting, I would like to perform some shorter audits of projects
like these alongside the longer audits listed above.&lt;/p>
&lt;p>If you don&amp;rsquo;t see your project on this list, but you feel like you could benefit
from an audit in 2023, please &lt;a href="https://zecsec.com/contact/">reach out&lt;/a> and I will do
my best to accommodate you!&lt;/p>
&lt;h2 id="security-side-projects">Security Side-Projects&lt;/h2>
&lt;p>In addition to security audits, there are a number of &amp;ldquo;side projects&amp;rdquo; I hope to
work on to support Zcash&amp;rsquo;s security.&lt;/p>
&lt;h3 id="office-hours-and-other-security-assistance-for-projects">Office Hours and Other Security Assistance for Projects&lt;/h3>
&lt;p>Anyone working in the Zcash ecosystem can now set up a private meeting with me
using &lt;a href="https://calendly.com/zecsec/zcash-security-meeting">my Calendly&lt;/a>.&lt;/p>
&lt;p>The kind of support projects can get this way includes:&lt;/p>
&lt;ul>
&lt;li>Getting early security feedback on designs and code.&lt;/li>
&lt;li>Help with responding to vulnerability reports.&lt;/li>
&lt;li>Incident response for attacks on infrastructure.&lt;/li>
&lt;li>Secure UX review of API designs and user interfaces.&lt;/li>
&lt;li>Getting answers to technical questions about the Zcash protocol.&lt;/li>
&lt;li>Anything else security- or -privacy-related, really!&lt;/li>
&lt;/ul>
&lt;p>In addition to supporting Zcash projects themselves, I will also be available
to the Zcash Grant Committee to support their decision-making by providing
technical or security-related input.&lt;/p>
&lt;h3 id="wallet-edge-cases">Wallet Edge Cases&lt;/h3>
&lt;p>A recommendation I&amp;rsquo;ve made in all of my wallet audits so far is to implement
better integration testing of wallets&amp;rsquo; state management in the face of edge
cases like reorgs, transactions failing to be mined, and other rare-but-possible
occurrences. Bugs in handling these kinds of edge cases could leave wallets in
invalid states, causing them to break or confuse users about how much funds they
have.&lt;/p>
&lt;p>The first step towards improving wallet testing is to enumerate all such edge
cases. With a complete list of edge cases, the quality of existing wallet tests
can be measured by determining which edge cases are covered and which are not.&lt;/p>
&lt;p>In 2023 I hope to release a nearly-complete edge case list, which can then be
used by wallet authors to improve their tests.&lt;/p>
&lt;h3 id="consensus-rule-labeling">Consensus Rule Labeling&lt;/h3>
&lt;p>A security engineer entering the Zcash ecosystem for the first time is faced
with the daunting task of &lt;em>finding&lt;/em> the code that implements Zcash&amp;rsquo;s consensus
rules. As a result, a large portion of audit time is used inefficiently, spent
finding and understanding consensus rule code.&lt;/p>
&lt;p>The efficiency of future consensus rule audits can be improved by labeling the
locations of all consensus rules in the code. Electric Coin Company has already
&lt;a href="https://github.com/zcash/zcash/pull/5912">started on this project&lt;/a>, and in 2023
I hope to advance it by labeling more consensus rules and &lt;a href="https://github.com/zcash/zcash/issues/6011">writing a linter for
the rule labeling format&lt;/a>.&lt;/p>
&lt;h3 id="secure-messaging-over-memos">Secure Messaging Over Memos&lt;/h3>
&lt;p>A popular use case for Zcash&amp;rsquo;s memo field is sending messages. However, Zcash&amp;rsquo;s
memo field currently lacks several properties that are required for secure
messaging. For example, it is not signed, so wallets cannot be sure of messages'
origins, and it is not forward-secure, so if keys are compromised all past
messages can be decrypted.&lt;/p>
&lt;p>In 2023, I hope to produce some design sketches that, if implemented, would make
it easier to build Signal-like secure messaging on top of Zcash. This project is
also a good candidate for a Zcash Community Grant RFP; I will be available to
assist the grant committee with writing up an RFP, if desired.&lt;/p>
&lt;h2 id="whats-left-out">What&amp;rsquo;s Left Out?&lt;/h2>
&lt;p>In my recently-published &lt;a href="https://zecsec.com/overview/">Zcash Ecosystem Security Overview&lt;/a> page, I laid out a list of big picture security and privacy
challenges for Zcash. The roadmap above touches on some of them, however there
are several that I &lt;em>probably won&amp;rsquo;t&lt;/em> have dedicated time for in 2023. They
deserve to be highlighted anyway:&lt;/p>
&lt;h3 id="scalable-privacy-for-wallets">Scalable Privacy for Wallets&lt;/h3>
&lt;p>A challenge faced by all cryptocurrencies that aim to offer strong, formal
privacy guarantees is: how can wallets&amp;rsquo; find their funds and make their funds
spendable quickly and efficiently?&lt;/p>
&lt;p>At present, Zcash uses &amp;ldquo;trial decryption&amp;rdquo;, where the wallet must try to decrypt
every transaction on the blockchain to find the ones that belong to it. There are many
alternatives to this design with varying levels of privacy and scalability.
I&amp;rsquo;ve surveyed them in my post, &lt;a href="https://zecsec.com/posts/scalable-private-money-needs-scalable-private-messaging/">Scalable Private Money Needs Scalable Anonymous Messaging&lt;/a>.&lt;/p>
&lt;h3 id="unintentional-andor-forced-use-of-transparent-transactions">Unintentional and/or Forced Use of Transparent Transactions&lt;/h3>
&lt;p>Usage of transparent transactions on the Zcash blockchain remains high.
Transparent addresses and transactions offer users the ability to transact
transparently, with consent, whenever they wish to do so. However, the high
transparent usage might be a sign that some users misunderstand the privacy
level provided by transparent transactions or that users are forced into making
parts of their transactions transparent, i.e. by third-parties who do not fully
support shielded addresses.&lt;/p>
&lt;p>I know of at least one anecdote where someone put themselves at risk by using a
transparent address, because they thought &amp;ldquo;Zcash is private.&amp;rdquo;&lt;/p>
&lt;p>In my view, this problem should be tackled with (a) research into how
frequently users misunderstand the privacy properties of using transparent
addresses, (b) UX design within wallets that communicates privacy levels clearly
and simply, (c) support requests from the community to third parties and extra
engineering effort to increase shielded adoption, (d) an eventual removal of
transparent addresses, replaced by the use of viewing keys.&lt;/p>
&lt;h3 id="mitigating-c-memory-corruption-bug-risk-in-zcashd">Mitigating C++ Memory Corruption Bug Risk in Zcashd&lt;/h3>
&lt;p>The main fullnode implementation of Zcash is written in C++, which puts it at
risk of entire classes of security vulnerabilities that cannot exist within
projects that are written in safer languages, like Rust. Deprecating the legacy
&lt;code>zcashd&lt;/code> codebase should be a priority, to be replaced by &lt;code>zebra&lt;/code>. These
risks could also be mitigated with better fuzzing of &lt;code>zcashd&lt;/code>&amp;rsquo;s code, but it&amp;rsquo;s
probably better to get rid of the C++ code entirely.&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>I&amp;rsquo;m looking forward to a productive year of security audits in 2023. Along with
the audits, I&amp;rsquo;m planning several side projects in support of Zcash&amp;rsquo;s security
like writing up better guidance for wallet testing, being more available to all
projects in office hours, working to label consensus rules, and exploring
improvements to the memo field for better secure messaging.&lt;/p>
&lt;p>Of course, all of these plans are subject to change in case new higher-priority
risks or projects appear, but this should give the community a good sense for
what to expect in the coming year.&lt;/p>
&lt;p>Let&amp;rsquo;s make the new year Zcash&amp;rsquo;s best year yet!&lt;/p></description><author>trandcanh@gmail.com (Calvin Tran)</author><guid>https://zecsec.com/posts/zecsec-roadmap-for-2023/</guid><pubDate>Tue, 03 Jan 2023 11:08:00 -0700</pubDate></item><item><title>YWallet Audit Results Published</title><link>https://zecsec.com/posts/ywallet-audit-published/</link><description>&lt;p>In October of last year, I reviewed &lt;a href="https://ywallet.app/">YWallet&lt;/a> for security
and privacy issues. This was the first audit I performed for the Zcash Ecosystem
Security grant.&lt;/p>
&lt;p>Today, the final report is being made available to the Zcash community at the
link below.&lt;/p>
&lt;p>The audit found one high-severity issue, two medium-severity issues, and several
low-severity issues. At this point in time, all issues have been remediated or
deemed to be safe to de-prioritize relative to other work.&lt;/p>
&lt;p>The high-severity issue was a problem with the way the wallet stored users'
contact lists in transaction memos. An attacker who knew a user&amp;rsquo;s address could
modify the user&amp;rsquo;s contact list by sending them specially-crafted memos. This
made it possible to carry out a man-in-the-middle between two users using
YWallet to chat with each other. The problem has been mitigated by only allowing
contact list updates from memos in transactions that were signed by the same
wallet. See the full report for details of the medium- and low-severity issues.&lt;/p>
&lt;p>The report highlights the general need for a memo signing standard as well as a
more-comprehensive suite of tests for Zcash wallets. These are priorities in my
&lt;a href="https://zecsec.com/posts/zecsec-roadmap-for-2023/">2023 roadmap&lt;/a>.&lt;/p>
&lt;p>Thanks to Ywallet&amp;rsquo;s author hanh for quick feedback on the report and fast bug fixes.&lt;/p>
&lt;p>&lt;a href="https://zecsec.com/audits/YWalletAuditReport-FINALv3.pdf">&lt;strong>YWallet Security and Privacy Analysis Report (PDF)&lt;/strong>&lt;/a>&lt;/p></description><author>trandcanh@gmail.com (Calvin Tran)</author><guid>https://zecsec.com/posts/ywallet-audit-published/</guid><pubDate>Tue, 03 Jan 2023 07:00:00 -0700</pubDate></item><item><title>Security Audit Process</title><link>https://zecsec.com/posts/security-audit-process/</link><description>&lt;p>In this post, I&amp;rsquo;m going to shed light on the process I follow to find bugs in my
audits of Zcash ecosystem software. Hopefully, this will be useful to you if you
are looking to understand more about how audits work or even learning how to
audit software yourself.&lt;/p>
&lt;p>The process I&amp;rsquo;m describing here should not be taken as gospel. Different
security auditors follow different processes, and I often deviate from this
process significantly to tailor my audits to the specific projects I am helping.&lt;/p>
&lt;h2 id="audit-process">Audit Process&lt;/h2>
&lt;h3 id="scoping-and-timeboxing">Scoping and Timeboxing&lt;/h3>
&lt;p>The first step in any audit is to understand &lt;em>what you&amp;rsquo;re auditing&lt;/em> and &lt;em>how
long you have to audit it&lt;/em>. This is crucial, because auditor-time is an
exceptionally rare resource, so it needs to be applied effectively and to the
right thing.&lt;/p>
&lt;p>In commercial engagements, the client and auditor often roughly agree on a
timeframe and budgeting (e.g. 2 weeks of auditing at $2,000 per auditor-day),
and have a back-and-forth discussion about the scope and sign mutual contracts
before the engagement begins. This is an inefficiency in the process that I
personally like to avoid, and thankfully past clients have trusted me to choose
my own scope, prioritizing what I feel is most important for the client. A
detailed scoping process makes sense whenever the client is already aware of
specific kinds of risks they need to mitigate, or if multiple auditors are being
hired to look at the same project and are to be tasked with different focus
areas.&lt;/p>
&lt;p>Out of this step in the process, you want to know how many days of paid time you
have, what general categories of bugs you&amp;rsquo;ll be looking for, and if anything is
off-limits (such as pen-testing production systems). You should also make it
clear up front whether or not the audit report will be published, as audit firms
are sometimes hesitant to do so, not wanting their report to be seen as a
&amp;ldquo;guarantee of security&amp;rdquo; or &amp;ldquo;stamp or approval&amp;rdquo;, and clients may not want their
mistakes to be publicized.&lt;/p>
&lt;h3 id="brainstorming--target-research">Brainstorming &amp;amp; Target Research&lt;/h3>
&lt;p>I see auditing as a creative process, so once any engagement begins, the first
thing I do is start brainstorming. Before I look at anything specific to the
target project, I think about what kind of project it is and try to enumerate
all the things that could possibly go wrong with &lt;em>that kind of thing&lt;/em>. For
example, if it&amp;rsquo;s an encryption program, I think about: weak key generation,
nonce reuse, weak encryption algorithms, lack of authentication, side-channel
attacks, and so on. I write all of these possibilities down. The point of this
exercise is to bring all of the things that &lt;em>might&lt;/em> go wrong into your
short-term memory so that they will stand out to you, if they actually &lt;em>have&lt;/em>
gone wrong, while you&amp;rsquo;re reading the relevant code.&lt;/p>
&lt;p>Next, I learn as much as I can about the target project without diving into
anything too technical. I read the docs, the changelog, issues that look
relevant to security on the issue tracker, google for past vulnerabilities, and
read any past audit reports of the project. I build and use the project, too. As
I am doing that, I keep expanding my brainstorm notes with new ideas that come to
mind.&lt;/p>
&lt;p>At the end of the brainstorming and research phase, you should have a list of
&lt;em>potential bugs&lt;/em> and &lt;em>attacker goals&lt;/em>. Your potential-bugs list is a brainstorm
that ideally includes all weaknesses that could possibly exist in the target
project (e.g. weak random number generator), and your attacker-goals list is a
brainstorm that ideally includes any goals an attacker might have (e.g. decrypt
the data).&lt;/p>
&lt;p>Your goal, during the audit, will be to find a set of weaknesses that an
attacker could exploit to accomplish their goal (e.g. the random number generator
produces weak keys, so an attacker can brute-force the key and decrypt the
data).&lt;/p>
&lt;h3 id="threat-modeling">Threat Modeling&lt;/h3>
&lt;p>At this point, you have a good understanding of what the target project is, what
weaknesses it might have, and the various ways attackers might try to attack its
users. If time permits, you can write up a formal (or at least detailed) threat
model for the project. If you do this right, it will help the developers
understand the security properties of their own software that they need to
maintain in the future, help users understand what security properties they&amp;rsquo;re
actually getting, and speed up future audits.&lt;/p>
&lt;p>There are many valid approaches to threat modeling, a common one is
&lt;a href="https://en.wikipedia.org/wiki/STRIDE_(security)">STRIDE&lt;/a>, however I prefer an
approach that I call &lt;a href="https://github.com/defuse/ictm">Invariant-Centric Threat
Modeling&lt;/a> which puts users first, requiring
security properties to be written in language that users can actually
understand, and considers it a &amp;ldquo;bug&amp;rdquo; if users ever think they are getting some
security property that they actually are not.&lt;/p>
&lt;h3 id="source-code-review">Source Code Review&lt;/h3>
&lt;p>Finally, the actual review process begins. I start by understanding the
directory structure of the project (the &lt;code>tree&lt;/code> command is very helpful!).
Then, I start reading code file-by-file. If there is an entrypoint to the
project (i.e. &lt;code>main())&lt;/code>), I will usually start there. But generally, I will
just read each file, in alphabetical order.&lt;/p>
&lt;p>You might be a little surprised by the fact I read the files in alphabetical
order. Wouldn&amp;rsquo;t it be better to &lt;em>understand&lt;/em> the program by tracing through call
stacks, understanding how classes relate to each other by drawing UML diagrams,
and so forth? In a time-crunched audit (as all audits are), this actually isn&amp;rsquo;t
the best use of time. It&amp;rsquo;s important to understand how the code you&amp;rsquo;re reading
fits in to the overall structure of the program, but if the code is well-written
and classes and functions are well-named, you can often correctly guess how it
fits in. In practice, I find most of my bugs in this linear scan of the code. A
linear scan of the code also guarantees a kind of completeness: you can be sure
that you&amp;rsquo;ve at least had your eyeballs pointed at every single line of code in
the project.&lt;/p>
&lt;p>For this to work, the brainstorming process mentioned above is essential.
Without it, problems won&amp;rsquo;t &amp;ldquo;jump out&amp;rdquo; at you as you are reading through the
code. It&amp;rsquo;s also important to &lt;em>continue&lt;/em> that same brainstorming process &lt;em>as&lt;/em> you
read the code, making note of any new ideas for potential problems that come to
mind as you are diving deeper into the code. Make notes, like &amp;ldquo;this function
returns -1 on error, if the caller doesn&amp;rsquo;t check it, a decryption error might be
unnoticed, is the caller actually checking it?&amp;rdquo;, instead of getting bogged down
confirming problems in this part of the process.&lt;/p>
&lt;p>After the first pass of source code review, you should have an expanded set of
notes with some potential issues, which you&amp;rsquo;ll want to check later. I use a star
system to help prioritize which possible problems are most-worth looking into
later, e.g. &amp;ldquo;*** it looks like it&amp;rsquo;s using &lt;code>rand()&lt;/code> to generate key!?&amp;rdquo;, &amp;ldquo;* make
sure the caller doesn&amp;rsquo;t pass a negative number here or else this will panic&amp;rdquo;.&lt;/p>
&lt;p>You should also be confused about a lot of things and have notes like &amp;ldquo;I don&amp;rsquo;t
get how this works!?&amp;rdquo;, &amp;ldquo;*** wtf how can this possibly be secure!!??&amp;rdquo;. In this stage,
we&amp;rsquo;ve been going for breadth and speed rather than depth and confirmation; this
is normal.&lt;/p>
&lt;p>This is a good point to pause and do even more brainstorming. Ask yourself &amp;ldquo;what
else could go wrong?&amp;rdquo;, &amp;ldquo;could any of the more-minor problems I&amp;rsquo;ve
identified be combined together to attack the system in bigger ways?&amp;rdquo;&lt;/p>
&lt;h3 id="check-priority-potential-issues">Check Priority Potential Issues&lt;/h3>
&lt;p>After reviewing most or all of the code, you should have a much better
understanding of how the code works, where things are, and a big list of TODOs:
possible problems and a bunch of things you&amp;rsquo;re really confused about. The next
step is to confirm some of those potential issues. This is the part where you
actually need to start tracing through call stacks, understanding classes'
relationships to each other, understanding if vulnerable-looking code is
actually something an attacker&amp;rsquo;s input can reach, and so on.&lt;/p>
&lt;p>If you&amp;rsquo;re really time-crunched, you won&amp;rsquo;t be able to check everything, so
prioritize by which problems you intuitively think are most likely to be &amp;ldquo;real&amp;rdquo;,
and by which kinds of problems would be the worst for the project&amp;rsquo;s users.&lt;/p>
&lt;p>A key thing to look for in this stage is the correctness (or incorrectness) of
how different components of the software interface with each other. This is
especially true when the different components were written by different people,
e.g. if your target software uses a library, you want to carefully read that
library&amp;rsquo;s documentation and make sure it&amp;rsquo;s being used correctly.&lt;/p>
&lt;p>At the end of this stage, you should have found the bulk of the issues which you
can begin writing up in your report.&lt;/p>
&lt;h3 id="deep-analysis-for-correctness">Deep Analysis for Correctness&lt;/h3>
&lt;p>Following the steps above will give you a broad and efficient coverage of the
entire project, and you will likely have found most of the bugs that will make
it into your report. For some kinds of code, it&amp;rsquo;s unavoidably necessary to dive
in much deeper and check that &lt;em>everything&lt;/em> is correct.&lt;/p>
&lt;p>&amp;ldquo;Correctness&amp;rdquo; means that the code always does what it is intended to, i.e. that
there are no bugs at all. As much as security engineers like to talk about
&amp;ldquo;security bugs&amp;rdquo; as a distinct category from &amp;ldquo;ordinary&amp;rdquo; kinds of bugs,
security is really about correctness. That&amp;rsquo;s because &lt;em>any&lt;/em> kind of bug, even
ones that seem benign, can potentially be used by an attacker to further their
goals.&lt;/p>
&lt;p>For certain kinds of code, especially cryptography, parsers, and anything
enforcing access control, there is no way to assure security except to deeply
understand and ensure the absolute correctness of all of the relevant code. The
modern way to do this is via formal verification, a computer-checkable proof
that the code will always do exactly what it is intended to do. Formal
verification is expensive to implement (but tools are getting better), and it
depends on having a detailed specification of what the code is &amp;ldquo;supposed to do&amp;rdquo;,
so it is not always a viable option.&lt;/p>
&lt;p>The next best thing is for a human&amp;mdash;the auditor&amp;mdash;to carefully check that
everything is correct. Based on the preceding stages, you should have a good
idea of which parts of the target program are ultra-security-critical and are
worthy of checking for correctness in extreme detail. The mindset to be in here
is that of someone trying to &lt;em>prove&lt;/em> the code is correct. Unless you are
absolutely, mathematically, convinced that the code is correct and conforms to
its specification, you still have more work to do.&lt;/p>
&lt;p>Doing this is extremely costly; whereas you might be able to get through a dozen
source code files in a day of normal review, it might take an entire day of
careful thinking to ensure the correctness of just one part of a cryptographic
algorithm or protocol.&lt;/p>
&lt;p>There are some tricks to avoid this, such as writing randomized tests to compare
two implementations of cryptographic primitives against each other, but to
whatever degree the relevant code is absolutely essential for security, you
often have to spend a lot of time checking its correctness.&lt;/p>
&lt;h3 id="the-writeup">The Writeup&lt;/h3>
&lt;p>At last, it&amp;rsquo;s time to write up the report. The format I like to use is:&lt;/p>
&lt;ol>
&lt;li>Introduction &amp;ndash; describe the audit scope and write up the threat model for the project (if they don&amp;rsquo;t already have one).&lt;/li>
&lt;li>Security &amp;amp; Privacy Findings &amp;ndash; list each issue that you&amp;rsquo;ve found, describing its severity and recommended prioritization, explaining it in detail, and recommend ways to fix it.&lt;/li>
&lt;li>Recommendations &amp;ndash; make suggestions to improve the overall quality of the code and/or speed up future audits.&lt;/li>
&lt;li>Good Things &amp;ndash; say genuine good things about the project/code, so that the report isn&amp;rsquo;t all negative.&lt;/li>
&lt;li>Future Work &amp;ndash; list the things you couldn&amp;rsquo;t cover in this audit, but should be covered by future audits. This section will be invaluable to future auditors.&lt;/li>
&lt;li>Conclusion &amp;ndash; summarize everything briefly.&lt;/li>
&lt;/ol>
&lt;h3 id="remediation--checking-the-fixes">Remediation &amp;amp; Checking the Fixes&lt;/h3>
&lt;p>It is common for fixes to reported security bugs to be incomplete or incorrect,
so it&amp;rsquo;s important to evaluate the fixes to the bugs you have reported. A really
common pattern is for developers to &amp;ldquo;block the exploit&amp;rdquo;, i.e. prevent one way of
exploiting the issue you described, without fixing the actual underlying
problem. I like to remain available to the developers of the projects I audit
until I&amp;rsquo;ve confirmed that all of the issues are fixed or we&amp;rsquo;ve mutually agreed a
fix is unnecessary or is safe to de-prioritize.&lt;/p>
&lt;h2 id="tooling--automation">Tooling &amp;amp; Automation&lt;/h2>
&lt;p>What I&amp;rsquo;ve described above is for a manual security review. Sometimes it&amp;rsquo;s
useful to use tools to assist with the audit process. However, I personally
haven&amp;rsquo;t found much success using security-specific tooling in my audits.
Anything an XSS or SQL injection scanner might find would definitely be found in
the manual review I would be doing anyway.&lt;/p>
&lt;p>There are some exceptions, where automation and tooling is really helpful:&lt;/p>
&lt;h3 id="unit-integration-and-regression-tests">Unit, Integration, and Regression Tests&lt;/h3>
&lt;p>A unit test or integration test of a software&amp;rsquo;s security property is worth a
thousand reviews, because it can be run automatically upon every change to the
software, perpetually ensuring that the property is satisfied.&lt;/p>
&lt;p>It might feel stupid, but make sure all the basic tests are in place, like &amp;ldquo;try
to decrypt the file with the wrong password&amp;rdquo; or &amp;ldquo;make the software connect to a
server with a self-signed certificate.&amp;rdquo; Even stupid tests will catch bugs
sometimes.&lt;/p>
&lt;p>Think about all the edge cases the target software might encounter, and
recommend that all of those edge cases be tested.&lt;/p>
&lt;p>Whenever a security bug is found, do the best you can to test for the presence
of that-or-similar bugs, so that if it ever gets re-introduced, it will be caught quickly.&lt;/p>
&lt;h3 id="dependency-update-checkers">Dependency Update Checkers&lt;/h3>
&lt;p>Tools like &lt;code>cargo audit&lt;/code>, &lt;code>./gradlew dependencyCheckAnalyze&lt;/code>, &lt;code>npm outdated&lt;/code> are invaluable for finding dependencies that are out of date or have
known vulnerabilities. These kinds of tools are available for most languages and
platforms, use them!&lt;/p>
&lt;h3 id="fuzzing">Fuzzing&lt;/h3>
&lt;p>Fuzzing is the process of using various types of algorithms to generate &amp;ldquo;random&amp;rdquo;
input to throw at your program to try to find bugs and crashes.
Counter-intuitively, fuzzing can be &lt;a href="https://lcamtuf.coredump.cx/afl/">incredibly successful at finding
bugs&lt;/a>, especially in projects written in
unsafe languages like C/C++.&lt;/p>
&lt;p>You can also &amp;ldquo;fuzz&amp;rdquo; implementations of cryptographic algorithms against each
other. If two implementations of a cipher or hash function, say, are supposed
to be equivalent, you can find differences between them by throwing the same
random data at both, as long as any &amp;ldquo;bug&amp;rdquo; occurs with a sufficiently high
probability.&lt;/p>
&lt;h2 id="to-write-exploits-or-not">To Write Exploits, or Not?&lt;/h2>
&lt;p>So far, I&amp;rsquo;ve written about how to find bugs, but what about exploiting them?
Exploitation is often the funnest part of security work, but it often isn&amp;rsquo;t
necessary. If the client understands the bug and is going to fix it, then it
usually isn&amp;rsquo;t worth the time to develop an exploit.&lt;/p>
&lt;p>The two exceptions are: (a) if the client doesn&amp;rsquo;t acknowledge the existence of a
bug and you need to prove it&amp;rsquo;s real, you need to write an exploit, and (b) if
you&amp;rsquo;ve got a severe bug on your hands, and you need to understand its
consequences or exploitability more-precisely, it can be beneficial to write an
exploit.&lt;/p>
&lt;p>I personally prefer to make false-positive errors in my security work than
false-negative errors. That is, if I&amp;rsquo;m unsure about the exploitability of a
given issue, I&amp;rsquo;ll include it in my report anyway, accepting a small chance that
I&amp;rsquo;m wrong. This saves the cost of rigorously proving the existence of the
problem, and makes sure that nothing that could be a real issue gets dropped.
The downside is that you might be embarrassed by reporting a bug that isn&amp;rsquo;t
real, but that&amp;rsquo;s better than the alternative.&lt;/p></description><author>trandcanh@gmail.com (Calvin Tran)</author><guid>https://zecsec.com/posts/security-audit-process/</guid><pubDate>Thu, 29 Dec 2022 07:00:00 -0700</pubDate></item><item><title>Scalable Private Money Needs Scalable Anonymous Messaging</title><link>https://zecsec.com/posts/scalable-private-money-needs-scalable-private-messaging/</link><description>&lt;p>In this post I’m going to argue that any scalable private Internet money system
will need to rely on an equally-scalable and equally-private anonymous messaging
system.&lt;/p>
&lt;p>Ultimately, I will argue that the best approach to scaling private money is to
&lt;em>directly and explicitly&lt;/em> build a scalable anonymous communication system,
rather than proceeding through a series of ad-hoc improvements to current
designs.&lt;/p>
&lt;h2 id="backstory">Backstory&lt;/h2>
&lt;p>The performance of Zcash mobile wallets has been degraded massively; this was
caused by a huge increase in private transaction load on the network. This
problem is not specific to Zcash—all private money systems aiming to offer
strong privacy guarantees will face this challenge eventually. To understand
why, we need to understand how the current best design for private Internet
money works.&lt;/p>
&lt;h2 id="protocol-recap">Protocol Recap&lt;/h2>
&lt;p>When Alice wants to send Bob a payment, Alice creates a &lt;em>note&lt;/em> containing the
value she wants to send to Bob. In her transaction, Alice posts three things to
the public blockchain: a note commitment, a zero-knowlege proof, and a note
ciphertext.&lt;/p>
&lt;p>The note commitment ties the newly-created note to Bob’s secret keys, so that
only Bob can spend the note. The zero-knowledge proof ensures that Alice is
creating the note honestly, i.e. she’s only creating it from money she controls,
and that she isn’t creating new money out of thin air.&lt;/p>
&lt;p>The third part, the note ciphertext, contains all of the information Bob
needs—along with his secret keys—to spend the value he has received from Alice.
A key-private encryption algorithm is used to create this ciphertext, which allows
Bob to decrypt it with his secret key, while ensuring nobody—even people who know
Bob’s address—can tell that the ciphertext belongs to Bob.&lt;/p>
&lt;h2 id="the-performance-bottleneck">The Performance Bottleneck&lt;/h2>
&lt;p>This design creates a scalability bottleneck: Bob has to try to decrypt every
ciphertext on the blockchain to find the notes that belong to him. When there
are a lot of new notes, his wallet will take a long time to get through them
all. In current implementations, it sometimes takes &lt;em>days&lt;/em> of trial-decrypting
to catch up with all of the transactions on the blockchain, depending on how far
behind the wallet is.&lt;/p>
&lt;p>This bottleneck isn’t all for nothing, it’s what gives the system its strong
privacy guarantees.&lt;/p>
&lt;p>The information Alice broadcasts in her transaction looks
like random noise, so although an attacker can tell &lt;em>that&lt;/em> Alice is sending a
transaction, the attacker can’t tell who it’s going to or what the amount is. On
Bob’s end, an attacker can tell &lt;em>that&lt;/em> Bob’s wallet has downloaded &lt;em>all
transactions in existence&lt;/em>, but the attacker cannot tell &lt;em>whether or not&lt;/em>, or
&lt;em>how many&lt;/em>, transactions Bob’s wallet actually received&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>This everyone-has-to-try-to-decrypt-everything bottleneck is inherent to all
private money designs that offer strong formal privacy guarantees. For these
systems to scale to thousands or millions of active users, trial decryption
needs to be replaced with something else.&lt;/p>
&lt;h2 id="private-money-implies-anonymous-messaging">Private Money Implies Anonymous Messaging&lt;/h2>
&lt;p>To overcome the trial-decryption bottleneck, Bob needs to be able to find out
about his notes—the money he is receiving—in an efficient way.&lt;/p>
&lt;p>We can show formally that solving this problem is closely related to a different
computer science problem: that of building an anonymous messaging system (also
known in the literature as an “anonymous communication network”).&lt;/p>
&lt;p>To see why, we can reduce the problem of building an anonymous messaging system
to the problem of building a private money system. That’s computer-science speak
for using the solution to Problem A (building a private money system) to
construct a solution for Problem B (building an anonymous messaging system);
doing so shows that Problem A is at least as hard as Problem B, i.e. to do A you
must do B. To build private money you must build anonymous communication.&lt;/p>
&lt;p>Given a private money system, any two users of the system can use it to message
each other privately and anonymously with the same privacy and anonymity
properties as the underlying private money system. They can do this by encoding
their messages into transaction values. If Alice wants to say “Hello” to Bob,
she can encode her message to the ASCII values 72, 101, 108, 108, 111 and send a
series of transactions with values 0.0072, 0.0101, 0.0108, 0.0108, 0.0111, plus
some zero-valued transactions to hide the length of the message. Simple, right?
Any private money system can be used as an anonymous communication system with
only a constant-factor performance overhead.&lt;/p>
&lt;p>What this means is that in order to build a private money system with certain
formal privacy and scalability properties, we are &lt;em>logically required&lt;/em> to build
an anonymous messaging system with at least those same privacy and scalability
properties. It also means that research on the trade-offs and limitations of
anonymous messaging systems apply to private money systems as well.&lt;/p>
&lt;p>In the other direction, we can &lt;em>use&lt;/em> a scalable anonymous messaging system to
overcome the trial-decryption bottleneck of our current private money designs.
Using the anonymous messaging system, Alice can send Bob the ciphertext directly
so that Bob doesn’t have to try to decrypt everything. When we do this, the
privacy and scalability properties of the resulting private money system are
&lt;em>limited&lt;/em> by the privacy and scalability properties of the anonymous
communication system.&lt;/p>
&lt;h2 id="what-are-our-options">What are our options?&lt;/h2>
&lt;p>Let’s look at a few of the options we have for replacing trial decryption.
There’s &lt;em>tons&lt;/em> of research on anonymous messaging systems, so I’m going to
restrict my attention here to options that are already on private-money
projects’ roadmaps or that seem promising to me.&lt;/p>
&lt;h3 id="smarter-scanning">Smarter Scanning&lt;/h3>
&lt;p>The option currently being pursued in Zcash is smarter scanning algorithms.
These algorithms must still eventually try to decrypt every ciphertext, but they
can find some of a user’s funds earlier, so that the user has some spendable
money and can make payments faster, without waiting for the entire scan to
complete. It won’t eliminate the long scanning times, but it will make user
experience significantly better.&lt;/p>
&lt;p>For more details, see
&lt;a href="https://hackmd.io/@str4d/dagsync-graph-aware-zcash-wallets">https://hackmd.io/@str4d/dagsync-graph-aware-zcash-wallets&lt;/a>.&lt;/p>
&lt;p>This is a good stopgap measure in the face of bricked wallets, but in the long
term, we will need something more.&lt;/p>
&lt;h3 id="scanning-in-the-cloud">Scanning in the Cloud&lt;/h3>
&lt;p>Another simple approach is to retain the trial-decryption paradigm, but move it
out of the smartphone and into the cloud, on beefier computers.&lt;/p>
&lt;p>This would retain all of the on-chain privacy properties of current protocol
designs, since there are no changes to the data stored on-chain. However, users’
wallets would need to send their decryption keys to the cloud. The user’s
privacy will only be as strong as the security of those cloud computers. (Note
that this can be done without giving &lt;em>spend authority&lt;/em> to the cloud servers, so
users&amp;rsquo; funds are safe.)&lt;/p>
&lt;p>If many users share the same cloud computer for scanning, that cloud computer
becomes an attractive target for adversaries who want to de-anonymize a mass of
users. That risk can be reduced somewhat by giving each wallet its own isolated
computer in the cloud, but this increases the cost and setup complexity for
users, and doesn’t isolate users against the mass-exploitation of a common bug
in the cloud setup.&lt;/p>
&lt;p>Users’ privacy can be protected further at the cost of increasing CPU load on
the servers with homomorphic-encryption-based &lt;a href="https://forum.zcashcommunity.com/t/oblivious-message-retrieval/40715">Oblivious Message Retrieval
(OMR)&lt;/a>.&lt;/p>
&lt;p>Cloud scanning is not a good long-term solution because it does not
fundamentally improve the system’s scalability, it just moves it to faster CPUs
(and perhaps later onto cloud GPUs). With enough usage, even scanning in the
cloud will not be fast enough, and will be too costly.&lt;/p>
&lt;h3 id="fuzzy-message-detection--other-decoy-systems">Fuzzy Message Detection (&amp;amp; Other Decoy Systems)&lt;/h3>
&lt;p>&lt;a href="https://eprint.iacr.org/2021/089">Fuzzy Message Detection&lt;/a> (FMD) is an
intermediate approach between all-on-the-device scanning and all-in-the-cloud
scanning.&lt;/p>
&lt;p>With FMD, the transaction recipient (or the consensus rules in
&lt;a href="https://protocol.penumbra.zone/main/crypto/fmd/sender-receiver.html">Penumbra’s
case&lt;/a>)
selects a false-positive rate and generates a detection key which is sent to the
cloud server. The cloud server uses the detection key to find all of the user’s
transactions, plus a collection of false positives at the chosen rate. The
server cannot tell which transactions legitimately belong to the user or are
false positives, so some uncertainty is created about which transactions belong
to the wallet.&lt;/p>
&lt;p>For a false positive rate P ∈ [0, 1], this reduces the amount of transactions
the wallet needs to scan locally by a factor of P. For example, a 1%
false-positive rate would make the wallet’s scanning 100x faster at the privacy
cost of giving the server a list of 99% of all transactions which &lt;em>definitely do
not&lt;/em> belong to the wallet.&lt;/p>
&lt;p>Unfortunately, we need to be skeptical of FMD’s privacy guarantees.&lt;/p>
&lt;p>The most pressing problem occurs when Alice sends transactions to Bob
repeatedly. An adversary who compromised the FMD server can collect strong
statistical evidence that Alice is paying Bob. For example, suppose that Alice
sends 100 transactions to Bob and the adversary knows all of those transactions
were created by Alice. Even for false-positive rates higher than 50% (less than
2x speedup), if &lt;em>none&lt;/em> of those transactions were going to Bob, the chance that
&lt;em>all&lt;/em> of them would be downloaded by Bob (as false positives) is less than 1 in
2^100. So, if the adversary sees Bob download them all, they can be nearly
certain Alice is sending payments to Bob, and privacy has been broken.&lt;/p>
&lt;p>This particular attack can be mitigated with sender-side anonymity protections,
removing the assumption that the adversary knows Alice created the transactions.
However, other desirable privacy properties remain broken. For example, if the
adversary wants to find out which wallet owns a particular address, they can
send that address 100 transactions and then observe which wallet retrieves all 100
of them.&lt;/p>
&lt;p>These attacks are symptoms of a more fundamental problem with FMD, which is that
decoy-based systems are incapable of ensuring formal privacy guarantees.&lt;/p>
&lt;p>In &lt;a href="https://arxiv.org/abs/1812.05638">On Privacy Notions in Anonymous
Communication&lt;/a>, the authors survey and
systematize desirable formal privacy notions for anonymous messaging. The
authors worked out the logical implications between all of the formal notions in
their systematization. They found that all of them imply a notion called
“sender-receiver pair unlinkability”. That means that if a system doesn’t have
sender-receiver pair unlinkability, it doesn’t have any of the other formal
privacy notions that they considered.&lt;/p>
&lt;p>A simplified version of sender-receiver unlinkability is defined by a game. In
the game, a secret bit is chosen at random. If the bit is 0, Sender 1 sends a
message to Receiver 1 and Sender 2 sends a message to Receiver 2. If the secret
bit is 1, the destinations are swapped; Sender 1 sends to Receiver 2 and Sender
2 sends to Receiver 1. To win the game, i.e. to break the privacy property, the
adversary has to guess the secret bit.&lt;/p>
&lt;p>With FMD in this four-user scenario, either the false-positive rate is high
enough that both receivers download both senders’ messages (meaning no
efficiency has been gained), or one receiver fails to download one of the
sender’s messages. Since there are no false-negatives in FMD, this means that
the not-downloaded sender’s message was definitely not directed at that
receiver, and the adversary learns the secret bit. For example, if Receiver 1
&lt;em>didn’t&lt;/em> download Sender 1’s message, then we know the bit is 1, since if it was
0, Receiver 1 would have definitely downloaded Sender 1’s message.&lt;/p>
&lt;p>This shows that FMD cannot satisfy sender-receiver pair unlinkability, and by
the logical implications given in the paper, cannot satisfy any of the other
formal privacy definitions. FMD’s privacy guarantees are necessarily heuristic
and statistical.&lt;/p>
&lt;p>More analysis of FMD’s privacy properties against weaker privacy notions can be
found in &lt;a href="https://arxiv.org/abs/2109.06576">The Effect of False Positives: Why Fuzzy Message Detection Leads to
Fuzzy Privacy Guarantees&lt;/a>.&lt;/p>
&lt;p>In addition to lackluster privacy properties, FMD is also not scalable. The FMD
server must still process all transactions for each user, and at best it offers
a constant factor reduction in the scanning work that wallets must perform
locally.&lt;/p>
&lt;h3 id="using-existing-communication-channels">Using Existing Communication Channels&lt;/h3>
&lt;p>If two users already talk to each other over an existing secure messaging
system, then they can send transactions over the messenger. For those
transactions (but not others), the recipient’s wallet can avoid
trial-decryption. This is the idea behind &lt;a href="https://github.com/zcash/zips/pull/420">liberated
payments&lt;/a>.&lt;/p>
&lt;p>This scales well, but has two drawbacks.&lt;/p>
&lt;p>First, the user experience is a significant departure from what is common among
cryptocurrencies. Users are accustomed to sending money to an address given to
them by their counterparty; with liberated payments, they would have to add
their counterparty as a contact on a messenger and get their wallet to send them
a message. I believe this can be made usable, but the sheer fact it works
differently might be enough to put a lot of users off.&lt;/p>
&lt;p>Second, the privacy properties of the resulting system are only as good as the
metadata-resistance privacy properties of the messengers used. For example, if a
transaction is sent through a messenger that uses strong encryption, but the
messenger leaks metadata about message size (identifying the message as likely
being a liberated payment) and who the message is coming from and going to, an
adversary watching this metadata can tell approximately who is sending payments
to who, breaking privacy guarantees that users expect.&lt;/p>
&lt;p>Liberated payments would work great for use cases where users are making
payments to a website, for example sending funds to an exchange, buying
something from an online store, or donating to a charity. In this case, any
attackers monitoring the user&amp;rsquo;s Internet connection are already aware that there
is some kind of relationship between the user and the website they have visited.
If the payment information is sent through the same encrypted connection that
the user&amp;rsquo;s browser is already using to communicate with the website, the fact a
payment is being made can be kept secret. If the payment information is sent
through a separate connection (e.g. from the user&amp;rsquo;s smartphone wallet, with the
payment being made by scanning a QR code in a desktop browser), the fact a
payment was made will be leaked, but this might not matter for some use cases,
like if the website is a store and the attacker is already pretty sure that the
user is going to buy something.&lt;/p>
&lt;p>So, liberated payments would work well as a workaround to wallet performance
problems for payments to websites and for a subset of users who already have a
private means to communicate with each other, but it may not be a good long-term
solution because of the metadata-privacy weaknesses in existing private
messengers and because it requires users to learn a new UX.&lt;/p>
&lt;h3 id="sgx-based-approaches">SGX-based Approaches&lt;/h3>
&lt;p>Another way to scale would be to use a trusted, private server. Using an actual
trusted server would defeat the purpose of building a private money system (we’d
just be building another PayPal), but Intel’s SGX technology aims to make it
possible to approximate a trusted server in an untrusted way. This is the
approach that &lt;a href="https://mobilecoin.com/">MobileCoin&lt;/a> takes (in combination with
the decoy-based CryptoNote protocol).&lt;/p>
&lt;p>Unfortunately, SGX’s security has been broken repeatedly by side-channel attacks
against the processor
(&lt;a href="https://www.usenix.org/conference/usenixsecurity18/presentation/bulck">some&lt;/a>
&lt;a href="https://sgaxe.com/">recent&lt;/a>
&lt;a href="https://ieeexplore.ieee.org/abstract/document/9152636">examples&lt;/a>). Like
copy-protection (“DRM”), what SGX is trying to do is fundamentally impossible.
The CPU itself needs access to the private bits in order to compute on them, so
it can &lt;em>only&lt;/em> be a matter of &lt;em>how hard&lt;/em> it is for an attacker to access those
bits, and how much resources they need to expend to do so. It is conceivable
that one day SGX will attain a state where all known attacks are practically
infeasible, but that’s currently not the case, and we don’t know when (if ever)
that will happen. The &lt;em>variety&lt;/em> of methods that have recently been used to break
SGX and alternatives like ARM TrustZone is good evidence that there are still
more vulnerabilities waiting to be found, so we should expect researchers to
develop more attacks in the coming years.&lt;/p>
&lt;p>In my opinion, the best way to think about SGX’s security is: “If the system’s
operators are mostly honest and aren’t too well-resourced, then you’re safe, but
if the NSA breaks in, or anyone with serious resources wants to break the
system, SGX will fail.” This is not a good long-term solution, at least not
until SGX or an equivalent technology has proven itself to resist all kinds of
attacks for a number of years.&lt;/p>
&lt;h3 id="tor">Tor&lt;/h3>
&lt;p>Tor is by far the most widely-used anonymous communication system in existence
today. Its focus is on providing low-latency connections at the expense of
formal privacy guarantees.&lt;/p>
&lt;p>Tor works by having the client select three “nodes” from the pool of available
nodes: an entry node, a relay node, and an exit node. The client encrypts its
message to the exit node’s key, encrypts that ciphertext to the relay node’s
key, and encrypts that ciphertext to the entry node’s key. The entry node can
decrypt the first layer of encryption and forward it onto the relay node, who
can decrypt one step further and forward it onto the exit node, who decrypts the
last layer and sends the data to the intended destination. The entry node knows
who the user is, the exit node knows where the traffic is going, and the relay
node prevents the entry and exit nodes from finding each other and colluding to
see who’s-sending-what-to-who. Tor also supports onion services, which allow the
service being connected-to to remain anonymous as well.&lt;/p>
&lt;p>Tor can be used to build anonymous messaging, a notable example being
&lt;a href="https://cwtch.im/">Cwtch&lt;/a>. In this way, it could be used to build an anonymous
messaging system in support of private money.&lt;/p>
&lt;p>However, Tor’s design explicitly trades-off worse privacy guarantees in order to
have lower latency. This is necessary for it to be suitable for browsing web
pages. But the low latency makes it vulnerable to timing attacks: after a client
sends a packet, it will shortly thereafter show up at its destination. If an
adversary is situated close to the client user (e.g. at an ISP), and also close
to the destination server (e.g. at an Amazon datacenter), they can collect
enough packet-timing information to statistically infer who’s talking to who. It
is well-known and accepted that Tor’s anonymity can be broken by global passive
adversaries, and adversaries situated at both endpoints, using attacks like
this. A &lt;a href="https://ieeexplore.ieee.org/abstract/document/9471821">recent paper&lt;/a>
surveys different kinds of de-anonymization attacks on Tor.&lt;/p>
&lt;p>Tor’s privacy properties are heuristic and are weaker than those that come
standard with projects like Zcash&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>; they are certainly insufficient for some use
cases of private Internet money. Therefore, extreme care needs to be taken with
any attempt to solve payment scalability problems with Tor. We must be mindful
that relying on Tor will mean giving up on formal privacy guarantees and will
make the system vulnerable to global passive adversaries, as well as adversaries
that are capable of monitoring the traffic of the set of wallets they are
interested in.&lt;/p>
&lt;h3 id="mixnets">Mixnets&lt;/h3>
&lt;p>As argued by the reduction given above, a private money system fundamentally
&lt;em>is&lt;/em> an anonymous messaging system. It therefore makes sense to look towards the
best designs for anonymous communication systems in the literature if we want to
solve private money systems’ scalability problems.&lt;/p>
&lt;p>This could be termed the “embrace the real problem” approach. Rather than
working through a series of ad-hoc strategies to scaling private money, all of
which come with their own scalability bottlenecks and privacy weaknesses, it
would be a more effective use of resources to work directly on solving the
&lt;em>necessary&lt;/em> problem of scaling anonymous communication.&lt;/p>
&lt;p>State-of-the-art designs for scalable anonymous messaging use mixnets. Mixnets
work by collecting users’ messages into batches and using a series of “mixnodes”
to shuffle the messages before delivering them to recipients’ mailboxes. By
shuffling messages in large batches (requiring high latency), and by using
sufficient chaff traffic, mixnets can provide provable privacy guarantees.&lt;/p>
&lt;p>Mixnets are not a panacea, however. Fundamental trade-offs apply, such as
between their privacy properties, latency of messages, efficiency, and offline
message availability. They are a newer technology, too, which hasn’t seen much
proven deployment in practice (&lt;a href="https://nymtech.net/">Nym&lt;/a> is one example).&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>In this post I’ve surveyed different approaches to solving private money
systems’ scalability problems. I&amp;rsquo;ve included those that I consider plausibly
viable as well as those on existing projects&amp;rsquo; roadmaps. A common theme among
many of them is that they are not asymptotic scaling solutions, only making
constant-factor improvements or moving the processing to faster computers. Most
of them don’t offer formal privacy guarantees or, worse, have known attacks that
make them unsuitable for Internet money. Others, like mixnets, are expensive and
risky to implement. There is no clear winner.&lt;/p>
&lt;p>What &lt;em>is&lt;/em> clear, though, is that scaling private payments &lt;em>is&lt;/em> scaling anonymous
messaging.&lt;/p>
&lt;p>We should therefore turn our attention toward the best designs available in the
scientific literature on anonymous communication, which in my view is currently
mixnet research.&lt;/p>
&lt;p>It’s unlikely that we will find an off-the-shelf solution, ready to be
implemented, that will solve all of our problems. We will need to make
significant investments in anonymous communication science and engineering over
the long term to make private money work. This is worth doing, because this way,
we are embracing the real, unavoidable, problem that lies ahead of us.&lt;/p>
&lt;p>(Some updates to this article were made on 2023-02-16.)&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>Note that current implementations of Zcash light wallets don’t take advantage
of these strong privacy properties, because Bob’s wallet will fetch extra
details of just those transactions that belong to him for the sake of bandwidth
savings. See the &lt;a href="https://zcash.readthedocs.io/en/latest/rtd_pages/wallet_threat_model.html">Zcash Wallet App Threat
Model&lt;/a>
for more details.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>At least using the full-node implementation.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description><author>trandcanh@gmail.com (Calvin Tran)</author><guid>https://zecsec.com/posts/scalable-private-money-needs-scalable-private-messaging/</guid><pubDate>Tue, 15 Nov 2022 19:00:00 -0700</pubDate></item><item><title>October Update: Ywallet audited, and what's next?</title><link>https://zecsec.com/posts/october-update/</link><description>&lt;p>Hi Zcash fans! It&amp;rsquo;s time for the first monthly update on the Zcash Ecosystem
Security grant. This October, we saw the completion of a full security audit of
&lt;a href="https://ywallet.app/">Ywallet&lt;/a>.&lt;/p>
&lt;p>Ywallet&amp;rsquo;s fast scanning algorithm makes it an attractive option for users facing
long delays due to the recent high usage of the Zcash blockchain. It had also
received the least security review among the Zcash wallets, so we
decided to prioritize it as the first project to be audited for this grant.&lt;/p>
&lt;p>The audit report was delivered to Ywallet&amp;rsquo;s developers today and it will be
published for the community to see after all necessary issues have been
appropriately remediated.&lt;/p>
&lt;h2 id="whats-next">What&amp;rsquo;s next?&lt;/h2>
&lt;p>In November, we will continue the focus on wallets, this time reviewing
&lt;a href="https://github.com/adityapk00/zecwallet-light-cli">zecwallet-lite-cli&lt;/a>. This
library and command-line tool is the basis of the popular ZecWallet-lite wallet.&lt;/p>
&lt;p>After this, we plan to take a short detour to focus on some of the smaller and
earlier-stage community projects, before putting our focus back on wallets to
review ZecWallet-lite proper, Nighthawk, and others.&lt;/p>
&lt;p>If you&amp;rsquo;d like your project to be included in our upcoming audit schedule, please
shoot an email to &lt;a href="mailto:zecsec@defuse.ca">zecsec@defuse.ca&lt;/a> with a link to your source code repository.&lt;/p></description><author>trandcanh@gmail.com (Calvin Tran)</author><guid>https://zecsec.com/posts/october-update/</guid><pubDate>Fri, 28 Oct 2022 08:13:14 -0700</pubDate></item><item><title>Hello, World!</title><link>https://zecsec.com/posts/my-first-post/</link><description>&lt;p>Hi!&lt;/p>
&lt;p>This is where I will be posting be posting updates on the &lt;a href="https://forum.zcashcommunity.com/t/zcash-ecosystem-security-lead/42090">Zcash Ecosystem
Security&lt;/a>
grant project!&lt;/p></description><author>trandcanh@gmail.com (Calvin Tran)</author><guid>https://zecsec.com/posts/my-first-post/</guid><pubDate>Thu, 13 Oct 2022 08:22:29 -0600</pubDate></item></channel></rss>